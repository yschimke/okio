{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Okio \u00b6 Okio is a library that complements java.io and java.nio to make it much easier to access, store, and process your data. It started as a component of OkHttp , the capable HTTP client included in Android. It\u2019s well-exercised and ready to solve new problems. ByteStrings and Buffers \u00b6 Okio is built around two types that pack a lot of capability into a straightforward API: ByteString is an immutable sequence of bytes. For character data, String is fundamental. ByteString is String\u2019s long-lost brother, making it easy to treat binary data as a value. This class is ergonomic: it knows how to encode and decode itself as hex, base64, and UTF-8. Buffer is a mutable sequence of bytes. Like ArrayList , you don\u2019t need to size your buffer in advance. You read and write buffers as a queue: write data to the end and read it from the front. There\u2019s no obligation to manage positions, limits, or capacities. Internally, ByteString and Buffer do some clever things to save CPU and memory. If you encode a UTF-8 string as a ByteString , it caches a reference to that string so that if you decode it later, there\u2019s no work to do. Buffer is implemented as a linked list of segments. When you move data from one buffer to another, it reassigns ownership of the segments rather than copying the data across. This approach is particularly helpful for multithreaded programs: a thread that talks to the network can exchange data with a worker thread without any copying or ceremony. Sources and Sinks \u00b6 An elegant part of the java.io design is how streams can be layered for transformations like encryption and compression. Okio includes its own stream types called Source and Sink that work like InputStream and OutputStream , but with some key differences: Timeouts. The streams provide access to the timeouts of the underlying I/O mechanism. Unlike the java.io socket streams, both read() and write() calls honor timeouts. Easy to implement. Source declares three methods: read() , close() , and timeout() . There are no hazards like available() or single-byte reads that cause correctness and performance surprises. Easy to use. Although implementations of Source and Sink have only three methods to write, callers are given a rich API with the BufferedSource and BufferedSink interfaces. These interfaces give you everything you need in one place. No artificial distinction between byte streams and char streams. It\u2019s all data. Read and write it as bytes, UTF-8 strings, big-endian 32-bit integers, little-endian shorts; whatever you want. No more InputStreamReader ! Easy to test. The Buffer class implements both BufferedSource and BufferedSink so your test code is simple and clear. Sources and sinks interoperate with InputStream and OutputStream . You can view any Source as an InputStream , and you can view any InputStream as a Source . Similarly for Sink and OutputStream . Presentations \u00b6 A Few \u201cOk\u201d Libraries ( slides ): An introduction to Okio and three libraries written with it. Decoding the Secrets of Binary Data ( slides ): How data encoding works and how Okio does it. Ok Multiplatform! ( slides ): How we changed Okio\u2019s implementation language from Java to Kotlin. Requirements \u00b6 Okio supports Android 4.0.3+ (API level 15+) and Java 7+. Okio depends on the Kotlin standard library . It is a small library with strong backward-compatibility. Recipes \u00b6 We\u2019ve written some recipes that demonstrate how to solve common problems with Okio. Read through them to learn about how everything works together. Cut-and-paste these examples freely; that\u2019s what they\u2019re for. Read a text file line-by-line ( Java / Kotlin ) \u00b6 Use Okio.source(File) to open a source stream to read a file. The returned Source interface is very small and has limited uses. Instead we wrap the source with a buffer. This has two benefits: It makes the API more powerful. Instead of the basic methods offered by Source , BufferedSource has dozens of methods to address most common problems concisely. It makes your program run faster. Buffering allows Okio to get more done with fewer I/O operations. Each Source that is opened needs to be closed. The code that opens the stream is responsible for making sure it is closed. Java Here we use Java\u2019s try blocks to close our sources automatically. public void readLines ( File file ) throws IOException { try ( Source fileSource = Okio . source ( file ); BufferedSource bufferedSource = Okio . buffer ( fileSource )) { while ( true ) { String line = bufferedSource . readUtf8Line (); if ( line == null ) break ; if ( line . contains ( \"square\" )) { System . out . println ( line ); } } } } Kotlin Note that static Okio methods become extension functions ( Okio.source(file) => file.source() ), and use is used to automatically close the streams: @Throws ( IOException :: class ) fun readLines ( file : File ) { file . source (). use { fileSource -> fileSource . buffer (). use { bufferedFileSource -> while ( true ) { val line = bufferedFileSource . readUtf8Line () ?: break if ( \"square\" in line ) { println ( line ) } } } } } The readUtf8Line() API reads all of the data until the next line delimiter \u2013 either \\n , \\r\\n , or the end of the file. It returns that data as a string, omitting the delimiter at the end. When it encounters empty lines the method will return an empty string. If there isn\u2019t any more data to read it will return null. The above program can be written more compactly by inlining the fileSource variable and by using a fancy for loop instead of a while : public void readLines ( File file ) throws IOException { try ( BufferedSource source = Okio . buffer ( Okio . source ( file ))) { for ( String line ; ( line = source . readUtf8Line ()) != null ; ) { if ( line . contains ( \"square\" )) { System . out . println ( line ); } } } } In Kotlin, we can wrap invocations of source.readUtf8Line() into the generateSequence builder to create a sequence of lines that will end once null is returned. Plus, transforming streams is easy thanks to the extension functions: @Throws ( IOException :: class ) fun readLines ( file : File ) { file . source (). buffer (). use { source -> generateSequence { source . readUtf8Line () } . filter { line -> \"square\" in line } . forEach ( :: println ) } } The readUtf8Line() method is suitable for parsing most files. For certain use-cases you may also consider readUtf8LineStrict() . It is similar but it requires that each line is terminated by \\n or \\r\\n . If it encounters the end of the file before that it will throw an EOFException . The strict variant also permits a byte limit to defend against malformed input. public void readLines ( File file ) throws IOException { try ( BufferedSource source = Okio . buffer ( Okio . source ( file ))) { while ( ! source . exhausted ()) { String line = source . readUtf8LineStrict ( 1024L ); if ( line . contains ( \"square\" )) { System . out . println ( line ); } } } } Here\u2019s a similar example written in Kotlin: @Throws ( IOException :: class ) fun readLines ( file : File ) { file . source (). buffer (). use { source -> while (! source . exhausted ()) { val line = source . readUtf8LineStrict ( 1024 ) if ( \"square\" in line ) { println ( line ) } } } } Write a text file ( Java / Kotlin ) \u00b6 Above we used a Source and a BufferedSource to read a file. To write, we use a Sink and a BufferedSink . The advantages of buffering are the same: a more capable API and better performance. public void writeEnv ( File file ) throws IOException { try ( Sink fileSink = Okio . sink ( file ); BufferedSink bufferedSink = Okio . buffer ( fileSink )) { for ( Map . Entry < String , String > entry : System . getenv (). entrySet ()) { bufferedSink . writeUtf8 ( entry . getKey ()); bufferedSink . writeUtf8 ( \"=\" ); bufferedSink . writeUtf8 ( entry . getValue ()); bufferedSink . writeUtf8 ( \"\\n\" ); } } } There isn\u2019t an API to write a line of input; instead we manually insert our own newline character. Most programs should hardcode \"\\n\" as the newline character. In rare situations you may use System.lineSeparator() instead of \"\\n\" : it returns \"\\r\\n\" on Windows and \"\\n\" everywhere else. We can write the above program more compactly by inlining the fileSink variable and by taking advantage of method chaining: Java public void writeEnv ( File file ) throws IOException { try ( BufferedSink sink = Okio . buffer ( Okio . sink ( file ))) { for ( Map . Entry < String , String > entry : System . getenv (). entrySet ()) { sink . writeUtf8 ( entry . getKey ()) . writeUtf8 ( \"=\" ) . writeUtf8 ( entry . getValue ()) . writeUtf8 ( \"\\n\" ); } } } Kotlin @Throws ( IOException :: class ) fun writeEnv ( file : File ) { file . sink (). buffer (). use { sink -> for (( key , value ) in System . getenv ()) { sink . writeUtf8 ( key ) sink . writeUtf8 ( \"=\" ) sink . writeUtf8 ( value ) sink . writeUtf8 ( \"\\n\" ) } } } In the above code we make four calls to writeUtf8() . Making four calls is more efficient than the code below because the VM doesn\u2019t have to create and garbage collect a temporary string. sink . writeUtf8 ( entry . getKey () + \"=\" + entry . getValue () + \"\\n\" ); // Slower! UTF-8 ( Java / Kotlin ) \u00b6 In the above APIs you can see that Okio really likes UTF-8. Early computer systems suffered many incompatible character encodings: ISO-8859-1, ShiftJIS, ASCII, EBCDIC, etc. Writing software to support multiple character sets was awful and we didn\u2019t even have emoji! Today we\u2019re lucky that the world has standardized on UTF-8 everywhere, with some rare uses of other charsets in legacy systems. If you need another character set, readString() and writeString() are there for you. These methods require that you specify a character set. Otherwise you may accidentally create data that is only readable by the local computer. Most programs should use the UTF-8 methods only. When encoding strings you need to be mindful of the different ways that strings are represented and encoded. When a glyph has an accent or another adornment it may be represented as a single complex code point ( \u00e9 ) or as a simple code point ( e ) followed by its modifiers ( \u00b4 ). When the entire glyph is a single code point that\u2019s called NFC ; when it\u2019s multiple it\u2019s NFD . Though we use UTF-8 whenever we read or write strings in I/O, when they are in memory Java Strings use an obsolete character encoding called UTF-16. It is a bad encoding because it uses a 16-bit char for most characters, but some don\u2019t fit. In particular, most emoji use two Java chars. This is problematic because String.length() returns a surprising result: the number of UTF-16 chars and not the natural number of glyphs. Caf\u00e9 \ud83c\udf69 Cafe\u0301 \ud83c\udf69 Form NFC NFD Code Points c a f \u00e9 \u2423 \ud83c\udf69 c a f e \u00b4 \u2423 \ud83c\udf69 UTF-8 bytes 43 61 66 c3a9 20 f09f8da9 43 61 66 65 cc81 20 f09f8da9 String.codePointCount 6 7 String.length 7 8 Utf8.size 10 11 For the most part Okio lets you ignore these problems and focus on your data. But when you need them, there are convenient APIs for dealing with low-level UTF-8 strings. Use Utf8.size() to count the number of bytes required to encode a string as UTF-8 without actually encoding it. This is handy in length-prefixed encodings like protocol buffers. Use BufferedSource.readUtf8CodePoint() to read a single variable-length code point, and BufferedSink.writeUtf8CodePoint() to write one. Golden Values ( Java / Kotlin ) \u00b6 Okio likes testing. The library itself is heavily tested, and it has features that are often helpful when testing application code. One pattern we\u2019ve found to be quite useful is \u201cgolden value\u201d testing. The goal of such tests is to confirm that data encoded with earlier versions of a program can safely be decoded by the current program. We\u2019ll illustrate this by encoding a value using Java Serialization. Though we must disclaim that Java Serialization is an awful encoding system and most programs should prefer other formats like JSON or protobuf! In any case, here\u2019s a method that takes an object, serializes it, and returns the result as a ByteString : Java private ByteString serialize ( Object o ) throws IOException { Buffer buffer = new Buffer (); try ( ObjectOutputStream objectOut = new ObjectOutputStream ( buffer . outputStream ())) { objectOut . writeObject ( o ); } return buffer . readByteString (); } Kotlin @Throws ( IOException :: class ) private fun serialize ( o : Any ?): ByteString { val buffer = Buffer () ObjectOutputStream ( buffer . outputStream ()). use { objectOut -> objectOut . writeObject ( o ) } return buffer . readByteString () } There\u2019s a lot going on here. We create a buffer as a holding space for our serialized data. It\u2019s a convenient replacement for ByteArrayOutputStream . We ask the buffer for its output stream. Writes to a buffer or its output stream always append data to the end of the buffer. We create an ObjectOutputStream (the encoding API for Java serialization) and write our object. The try block takes care of closing the stream for us. Note that closing a buffer has no effect. Finally we read a byte string from the buffer. The readByteString() method allows us to specify how many bytes to read; here we don\u2019t specify a count in order to read the entire thing. Reads from a buffer always consume data from the front of the buffer. With our serialize() method handy we are ready to compute and print a golden value. Java Point point = new Point ( 8.0 , 15.0 ); ByteString pointBytes = serialize ( point ); System . out . println ( pointBytes . base64 ()); Kotlin val point = Point ( 8.0 , 15.0 ) val pointBytes = serialize ( point ) println ( pointBytes . base64 ()) We print the ByteString as base64 because it\u2019s a compact format that\u2019s suitable for embedding in a test case. The program prints this: rO0ABXNyAB5va2lvLnNhbXBsZXMuR29sZGVuVmFsdWUkUG9pbnTdUW8rMji1IwIAAkQAAXhEAAF5eHBAIAAAAAAAAEAuAAAAAAAA That\u2019s our golden value! We can embed it in our test case using base64 again to convert it back into a ByteString : Java ByteString goldenBytes = ByteString . decodeBase64 ( \"rO0ABXNyAB5va2lvLnNhbXBsZ\" + \"XMuR29sZGVuVmFsdWUkUG9pbnTdUW8rMji1IwIAAkQAAXhEAAF5eHBAIAAAAAAAAEAuA\" + \"AAAAAAA\" ); Kotlin val goldenBytes = ( \"rO0ABXNyACRva2lvLnNhbXBsZXMuS290bGluR29sZGVuVmFsdWUkUG9pbnRF9yaY7cJ9EwIAA\" + \"kQAAXhEAAF5eHBAIAAAAAAAAEAuAAAAAAAA\" ). decodeBase64 () The next step is to deserialize the ByteString back into our value class. This method reverses the serialize() method above: we append a byte string to a buffer then consume it using an ObjectInputStream : Java private Object deserialize ( ByteString byteString ) throws IOException , ClassNotFoundException { Buffer buffer = new Buffer (); buffer . write ( byteString ); try ( ObjectInputStream objectIn = new ObjectInputStream ( buffer . inputStream ())) { return objectIn . readObject (); } } Kotlin @Throws ( IOException :: class , ClassNotFoundException :: class ) private fun deserialize ( byteString : ByteString ): Any ? { val buffer = Buffer () buffer . write ( byteString ) ObjectInputStream ( buffer . inputStream ()). use { objectIn -> return objectIn . readObject () } } Now we can test the decoder against the golden value: Java ByteString goldenBytes = ByteString . decodeBase64 ( \"rO0ABXNyAB5va2lvLnNhbXBsZ\" + \"XMuR29sZGVuVmFsdWUkUG9pbnTdUW8rMji1IwIAAkQAAXhEAAF5eHBAIAAAAAAAAEAuA\" + \"AAAAAAA\" ); Point decoded = ( Point ) deserialize ( goldenBytes ); assertEquals ( new Point ( 8.0 , 15.0 ), decoded ); Kotlin val goldenBytes = ( \"rO0ABXNyACRva2lvLnNhbXBsZXMuS290bGluR29sZGVuVmFsdWUkUG9pbnRF9yaY7cJ9EwIAA\" + \"kQAAXhEAAF5eHBAIAAAAAAAAEAuAAAAAAAA\" ). decodeBase64 () !! val decoded = deserialize ( goldenBytes ) as Point assertEquals ( point , decoded ) With this test we can change the serialization of the Point class without breaking compatibility. Write a binary file ( Java / Kotlin ) \u00b6 Encoding a binary file is not unlike encoding a text file. Okio uses the same BufferedSink and BufferedSource bytes for both. This is handy for binary formats that include both byte and character data. Writing binary data is more hazardous than text because if you make a mistake it is often quite difficult to diagnose. Avoid such mistakes by being careful around these traps: The width of each field. This is the number of bytes used. Okio doesn\u2019t include a mechanism to emit partial bytes. If you need that, you\u2019ll need to do your own bit shifting and masking before writing. The endianness of each field. All fields that have more than one byte have endianness : whether the bytes are ordered most-significant to least (big endian) or least-significant to most (little endian). Okio uses the Le suffix for little-endian methods; methods without a suffix are big-endian. Signed vs. Unsigned. Java doesn\u2019t have unsigned primitive types (except for char !) so coping with this is often something that happens at the application layer. To make this a little easier Okio accepts int types for writeByte() and writeShort() . You can pass an \u201cunsigned\u201d byte like 255 and Okio will do the right thing. Method Width Endianness Value Encoded Value writeByte 1 3 03 writeShort 2 big 3 00 03 writeInt 4 big 3 00 00 00 03 writeLong 8 big 3 00 00 00 00 00 00 00 03 writeShortLe 2 little 3 03 00 writeIntLe 4 little 3 03 00 00 00 writeLongLe 8 little 3 03 00 00 00 00 00 00 00 writeByte 1 Byte.MAX_VALUE 7f writeShort 2 big Short.MAX_VALUE 7f ff writeInt 4 big Int.MAX_VALUE 7f ff ff ff writeLong 8 big Long.MAX_VALUE 7f ff ff ff ff ff ff ff writeShortLe 2 little Short.MAX_VALUE ff 7f writeIntLe 4 little Int.MAX_VALUE ff ff ff 7f writeLongLe 8 little Long.MAX_VALUE ff ff ff ff ff ff ff 7f This code encodes a bitmap following the BMP file format . Java void encode ( Bitmap bitmap , BufferedSink sink ) throws IOException { int height = bitmap . height (); int width = bitmap . width (); int bytesPerPixel = 3 ; int rowByteCountWithoutPadding = ( bytesPerPixel * width ); int rowByteCount = (( rowByteCountWithoutPadding + 3 ) / 4 ) * 4 ; int pixelDataSize = rowByteCount * height ; int bmpHeaderSize = 14 ; int dibHeaderSize = 40 ; // BMP Header sink . writeUtf8 ( \"BM\" ); // ID. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize + pixelDataSize ); // File size. sink . writeShortLe ( 0 ); // Unused. sink . writeShortLe ( 0 ); // Unused. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize ); // Offset of pixel data. // DIB Header sink . writeIntLe ( dibHeaderSize ); sink . writeIntLe ( width ); sink . writeIntLe ( height ); sink . writeShortLe ( 1 ); // Color plane count. sink . writeShortLe ( bytesPerPixel * Byte . SIZE ); sink . writeIntLe ( 0 ); // No compression. sink . writeIntLe ( 16 ); // Size of bitmap data including padding. sink . writeIntLe ( 2835 ); // Horizontal print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 2835 ); // Vertical print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 0 ); // Palette color count. sink . writeIntLe ( 0 ); // 0 important colors. // Pixel data. for ( int y = height - 1 ; y >= 0 ; y -- ) { for ( int x = 0 ; x < width ; x ++ ) { sink . writeByte ( bitmap . blue ( x , y )); sink . writeByte ( bitmap . green ( x , y )); sink . writeByte ( bitmap . red ( x , y )); } // Padding for 4-byte alignment. for ( int p = rowByteCountWithoutPadding ; p < rowByteCount ; p ++ ) { sink . writeByte ( 0 ); } } } Kotlin @Throws ( IOException :: class ) fun encode ( bitmap : Bitmap , sink : BufferedSink ) { val height = bitmap . height val width = bitmap . width val bytesPerPixel = 3 val rowByteCountWithoutPadding = bytesPerPixel * width val rowByteCount = ( rowByteCountWithoutPadding + 3 ) / 4 * 4 val pixelDataSize = rowByteCount * height val bmpHeaderSize = 14 val dibHeaderSize = 40 // BMP Header sink . writeUtf8 ( \"BM\" ) // ID. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize + pixelDataSize ) // File size. sink . writeShortLe ( 0 ) // Unused. sink . writeShortLe ( 0 ) // Unused. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize ) // Offset of pixel data. // DIB Header sink . writeIntLe ( dibHeaderSize ) sink . writeIntLe ( width ) sink . writeIntLe ( height ) sink . writeShortLe ( 1 ) // Color plane count. sink . writeShortLe ( bytesPerPixel * Byte . SIZE_BITS ) sink . writeIntLe ( 0 ) // No compression. sink . writeIntLe ( 16 ) // Size of bitmap data including padding. sink . writeIntLe ( 2835 ) // Horizontal print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 2835 ) // Vertical print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 0 ) // Palette color count. sink . writeIntLe ( 0 ) // 0 important colors. // Pixel data. for ( y in height - 1 downTo 0 ) { for ( x in 0 until width ) { sink . writeByte ( bitmap . blue ( x , y )) sink . writeByte ( bitmap . green ( x , y )) sink . writeByte ( bitmap . red ( x , y )) } // Padding for 4-byte alignment. for ( p in rowByteCountWithoutPadding until rowByteCount ) { sink . writeByte ( 0 ) } } } The trickiest part of this program is the format\u2019s required padding. The BMP format expects each row to begin on a 4-byte boundary so it is necessary to add zeros to maintain the alignment. Encoding other binary formats is usually quite similar. Some tips: Write tests with golden values! Confirming that your program emits the expected result can make debugging easier. Use Utf8.size() to compute the number of bytes of an encoded string. This is essential for length-prefixed formats. Use Float.floatToIntBits() and Double.doubleToLongBits() to encode floating point values. Communicate on a Socket ( Java / Kotlin ) \u00b6 Sending and receiving data over the network is a bit like writing and reading files. We use BufferedSink to encode output and BufferedSource to decode input. Like files, network protocols can be text, binary, or a mix of both. But there are also some substantial differences between the network and the filesystem. With a file you\u2019re either reading or writing but with the network you can do both! Some protocols handle this by taking turns: write a request, read a response, repeat. You can implement this kind of protocol with a single thread. In other protocols you may read and write simultaneously. Typically you\u2019ll want one dedicated thread for reading. For writing you can use either a dedicated thread or use synchronized so that multiple threads can share a sink. Okio\u2019s streams are not safe for concurrent use. Sinks buffer outbound data to minimize I/O operations. This is efficient but it means you must manually call flush() to transmit data. Typically message-oriented protocols flush after each message. Note that Okio will automatically flush when the buffered data exceeds some threshold. This is intended to save memory and you shouldn\u2019t rely on it for interactive protocols. Okio builds on java.io.Socket for connectivity. Create your socket as a server or as a client, then use Okio.source(Socket) to read and Okio.sink(Socket) to write. These APIs also work with SSLSocket . You should use SSL unless you have a very good reason not to! Cancel a socket from any thread by calling Socket.close() ; this will cause its sources and sinks to immediately fail with an IOException . You can also configure timeouts for all socket operations. You don\u2019t need a reference to the socket to adjust timeouts: Source and Sink expose timeouts directly. This API works even if the streams are decorated. As a complete example of networking with Okio we wrote a basic SOCKS proxy server. Some highlights: Java Socket fromSocket = ... BufferedSource fromSource = Okio . buffer ( Okio . source ( fromSocket )); BufferedSink fromSink = Okio . buffer ( Okio . sink ( fromSocket )); Kotlin val fromSocket : Socket = ... val fromSource = fromSocket . source (). buffer () val fromSink = fromSocket . sink (). buffer () Creating sources and sinks for sockets is the same as creating them for files. Once you create a Source or Sink for a socket you must not use its InputStream or OutputStream , respectively. Java Buffer buffer = new Buffer (); for ( long byteCount ; ( byteCount = source . read ( buffer , 8192L )) != - 1 ; ) { sink . write ( buffer , byteCount ); sink . flush (); } Kotlin val buffer = Buffer () var byteCount : Long while ( source . read ( buffer , 8192L ). also { byteCount = it } != - 1L ) { sink . write ( buffer , byteCount ) sink . flush () } The above loop copies data from the source to the sink, flushing after each read. If we didn\u2019t need the flushing we could replace this loop with a single call to BufferedSink.writeAll(Source) . The 8192 argument to read() is the maximum number of bytes to read before returning. We could have passed any value here, but we like 8 KiB because that\u2019s the largest value Okio can do in a single system call. Most of the time application code doesn\u2019t need to deal with such limits! Java int addressType = fromSource . readByte () & 0xff ; int port = fromSource . readShort () & 0xffff ; Kotlin val addressType = fromSource . readByte (). toInt () and 0 xff val port = fromSource . readShort (). toInt () and 0 xffff Okio uses signed types like byte and short , but often protocols want unsigned values. The bitwise & operator is Java\u2019s preferred idiom to convert a signed value into an unsigned value. Here\u2019s a cheat sheet for bytes, shorts, and ints: Type Signed Range Unsigned Range Signed to Unsigned byte -128..127 0..255 int u = s & 0xff; short -32,768..32,767 0..65,535 int u = s & 0xffff; int -2,147,483,648..2,147,483,647 0..4,294,967,295 long u = s & 0xffffffffL; Java has no primitive type that can represent unsigned longs. Hashing ( Java / Kotlin ) \u00b6 We\u2019re bombarded by hashing in our lives as Java programmers. Early on we\u2019re introduced to the hashCode() method, something we know we need to override otherwise unforeseen bad things happen. Later we\u2019re shown LinkedHashMap and its friends. These build on that hashCode() method to organize data for fast retrieval. Elsewhere we have cryptographic hash functions. These get used all over the place. HTTPS certificates, Git commits, BitTorrent integrity checking, and Blockchain blocks all use cryptographic hashes. Good use of hashes can improve the performance, privacy, security, and simplicity of an application. Each cryptographic hash function accepts a variable-length stream of input bytes and produces a fixed-length byte string value called the \u201chash\u201d. Hash functions have these important qualities: Deterministic: each input always produces the same output. Uniform: each output byte string is equally likely. It is very difficult to find or create pairs of different inputs that yield the same output. This is called a \u201ccollision\u201d. Non-reversible: knowing an output doesn\u2019t help you to find the input. Note that if you know some possible inputs you can hash them to see if their hashes match. Well-known: the hash is implemented everywhere and rigorously understood. Good hash functions are very cheap to compute (dozens of microseconds) and expensive to reverse (quintillions of millenia). Steady advances in computing and mathematics have caused once-great hash functions to become inexpensive to reverse. When choosing a hash function, beware that not all are created equal! Okio supports these well-known cryptographic hash functions: MD5 : a 128-bit (16 byte) cryptographic hash. It is both insecure and obsolete because it is inexpensive to reverse! This hash is offered because it is popular and convenient for use in legacy systems that are not security-sensitive. SHA-1 : a 160-bit (20 byte) cryptographic hash. It was recently demonstrated that it is feasible to create SHA-1 collisions. Consider upgrading from SHA-1 to SHA-256. SHA-256 : a 256-bit (32 byte) cryptographic hash. SHA-256 is widely understood and expensive to reverse. This is the hash most systems should use. SHA-512 : a 512-bit (64 byte) cryptographic hash. It is expensive to reverse. Each hash creates a ByteString of the specified length. Use hex() to get the conventional human-readable form. Or leave it as a ByteString because that\u2019s a convenient model type! Okio can produce cryptographic hashes from byte strings: Java ByteString byteString = readByteString ( new File ( \"README.md\" )); System . out . println ( \" md5: \" + byteString . md5 (). hex ()); System . out . println ( \" sha1: \" + byteString . sha1 (). hex ()); System . out . println ( \"sha256: \" + byteString . sha256 (). hex ()); System . out . println ( \"sha512: \" + byteString . sha512 (). hex ()); Kotlin val byteString = readByteString ( File ( \"README.md\" )) println ( \" md5: \" + byteString . md5 (). hex ()) println ( \" sha1: \" + byteString . sha1 (). hex ()) println ( \" sha256: \" + byteString . sha256 (). hex ()) println ( \" sha512: \" + byteString . sha512 (). hex ()) From buffers: Java Buffer buffer = readBuffer ( new File ( \"README.md\" )); System . out . println ( \" md5: \" + buffer . md5 (). hex ()); System . out . println ( \" sha1: \" + buffer . sha1 (). hex ()); System . out . println ( \"sha256: \" + buffer . sha256 (). hex ()); System . out . println ( \"sha512: \" + buffer . sha512 (). hex ()); Kotlin val buffer = readBuffer ( File ( \"README.md\" )) println ( \" md5: \" + buffer . md5 (). hex ()) println ( \" sha1: \" + buffer . sha1 (). hex ()) println ( \" sha256: \" + buffer . sha256 (). hex ()) println ( \" sha512: \" + buffer . sha512 (). hex ()) While streaming from a source: Java try ( HashingSink hashingSink = HashingSink . sha256 ( Okio . blackhole ()); BufferedSource source = Okio . buffer ( Okio . source ( file ))) { source . readAll ( hashingSink ); System . out . println ( \"sha256: \" + hashingSink . hash (). hex ()); } Kotlin sha256 ( blackholeSink ()). use { hashingSink -> file . source (). buffer (). use { source -> source . readAll ( hashingSink ) println ( \" sha256: \" + hashingSink . hash . hex ()) } } While streaming to a sink: Java try ( HashingSink hashingSink = HashingSink . sha256 ( Okio . blackhole ()); BufferedSink sink = Okio . buffer ( hashingSink ); Source source = Okio . source ( file )) { sink . writeAll ( source ); sink . close (); // Emit anything buffered. System . out . println ( \"sha256: \" + hashingSink . hash (). hex ()); } Kotlin sha256 ( blackholeSink ()). use { hashingSink -> hashingSink . buffer (). use { sink -> file . source (). use { source -> sink . writeAll ( source ) sink . close () // Emit anything buffered. println ( \" sha256: \" + hashingSink . hash . hex ()) } } } Okio also supports HMAC (Hash Message Authentication Code) which combines a secret and a hash. Applications use HMAC for data integrity and authentication. Java ByteString secret = ByteString . decodeHex ( \"7065616e7574627574746572\" ); System . out . println ( \"hmacSha256: \" + byteString . hmacSha256 ( secret ). hex ()); Kotlin val secret = \"7065616e7574627574746572\" . decodeHex () println ( \"hmacSha256: \" + byteString . hmacSha256 ( secret ). hex ()) As with hashing, you can generate an HMAC from a ByteString , Buffer , HashingSource , and HashingSink . Note that Okio doesn\u2019t implement HMAC for MD5. Okio uses Java\u2019s java.security.MessageDigest for cryptographic hashes and javax.crypto.Mac for HMAC. Encryption and Decryption \u00b6 Use Okio.cipherSink(Sink, Cipher) or Okio.cipherSource(Source, Cipher) to encrypt or decrypt a stream using a block cipher. Callers are responsible for the initialization of the encryption or decryption cipher with the chosen algorithm, the key, and algorithm-specific additional parameters like the initialization vector. The following example shows a typical usage with AES encryption, in which key and iv parameters should both be 16 bytes long. void encryptAes ( ByteString bytes , File file , byte [] key , byte [] iv ) throws GeneralSecurityException , IOException { Cipher cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ); cipher . init ( Cipher . ENCRYPT_MODE , new SecretKeySpec ( key , \"AES\" ), new IvParameterSpec ( iv )); try ( BufferedSink sink = Okio . buffer ( Okio . cipherSink ( Okio . sink ( file ), cipher ))) { sink . write ( bytes ); } } ByteString decryptAesToByteString ( File file , byte [] key , byte [] iv ) throws GeneralSecurityException , IOException { Cipher cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ); cipher . init ( Cipher . DECRYPT_MODE , new SecretKeySpec ( key , \"AES\" ), new IvParameterSpec ( iv )); try ( BufferedSource source = Okio . buffer ( Okio . cipherSource ( Okio . source ( file ), cipher ))) { return source . readByteString (); } } In Kotlin, these encryption and decryption methods are extensions on Cipher : fun encryptAes ( bytes : ByteString , file : File , key : ByteArray , iv : ByteArray ) { val cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ) cipher . init ( Cipher . ENCRYPT_MODE , SecretKeySpec ( key , \"AES\" ), IvParameterSpec ( iv )) val cipherSink = file . sink (). cipherSink ( cipher ) cipherSink . buffer (). use { it . write ( bytes ) } } fun decryptAesToByteString ( file : File , key : ByteArray , iv : ByteArray ): ByteString { val cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ) cipher . init ( Cipher . DECRYPT_MODE , SecretKeySpec ( key , \"AES\" ), IvParameterSpec ( iv )) val cipherSource = file . source (). cipherSource ( cipher ) return cipherSource . buffer (). use { it . readByteString () } } Releases \u00b6 Our change log has release history. implementation ( \"com.squareup.okio:okio:2.9.0\" ) Snapshot builds are also available repositories { maven { url = uri ( \"https://oss.sonatype.org/content/repositories/snapshots/\" ) } } dependencies { implementation ( \"com.squareup.okio:okio:2.9.0\" ) } R8 / ProGuard \u00b6 If you are using R8 or ProGuard add the options from this file . License \u00b6 Copyright 2013 Square, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Overview"},{"location":"#okio","text":"Okio is a library that complements java.io and java.nio to make it much easier to access, store, and process your data. It started as a component of OkHttp , the capable HTTP client included in Android. It\u2019s well-exercised and ready to solve new problems.","title":"Okio"},{"location":"#bytestrings-and-buffers","text":"Okio is built around two types that pack a lot of capability into a straightforward API: ByteString is an immutable sequence of bytes. For character data, String is fundamental. ByteString is String\u2019s long-lost brother, making it easy to treat binary data as a value. This class is ergonomic: it knows how to encode and decode itself as hex, base64, and UTF-8. Buffer is a mutable sequence of bytes. Like ArrayList , you don\u2019t need to size your buffer in advance. You read and write buffers as a queue: write data to the end and read it from the front. There\u2019s no obligation to manage positions, limits, or capacities. Internally, ByteString and Buffer do some clever things to save CPU and memory. If you encode a UTF-8 string as a ByteString , it caches a reference to that string so that if you decode it later, there\u2019s no work to do. Buffer is implemented as a linked list of segments. When you move data from one buffer to another, it reassigns ownership of the segments rather than copying the data across. This approach is particularly helpful for multithreaded programs: a thread that talks to the network can exchange data with a worker thread without any copying or ceremony.","title":"ByteStrings and Buffers"},{"location":"#sources-and-sinks","text":"An elegant part of the java.io design is how streams can be layered for transformations like encryption and compression. Okio includes its own stream types called Source and Sink that work like InputStream and OutputStream , but with some key differences: Timeouts. The streams provide access to the timeouts of the underlying I/O mechanism. Unlike the java.io socket streams, both read() and write() calls honor timeouts. Easy to implement. Source declares three methods: read() , close() , and timeout() . There are no hazards like available() or single-byte reads that cause correctness and performance surprises. Easy to use. Although implementations of Source and Sink have only three methods to write, callers are given a rich API with the BufferedSource and BufferedSink interfaces. These interfaces give you everything you need in one place. No artificial distinction between byte streams and char streams. It\u2019s all data. Read and write it as bytes, UTF-8 strings, big-endian 32-bit integers, little-endian shorts; whatever you want. No more InputStreamReader ! Easy to test. The Buffer class implements both BufferedSource and BufferedSink so your test code is simple and clear. Sources and sinks interoperate with InputStream and OutputStream . You can view any Source as an InputStream , and you can view any InputStream as a Source . Similarly for Sink and OutputStream .","title":"Sources and Sinks"},{"location":"#presentations","text":"A Few \u201cOk\u201d Libraries ( slides ): An introduction to Okio and three libraries written with it. Decoding the Secrets of Binary Data ( slides ): How data encoding works and how Okio does it. Ok Multiplatform! ( slides ): How we changed Okio\u2019s implementation language from Java to Kotlin.","title":"Presentations"},{"location":"#requirements","text":"Okio supports Android 4.0.3+ (API level 15+) and Java 7+. Okio depends on the Kotlin standard library . It is a small library with strong backward-compatibility.","title":"Requirements"},{"location":"#recipes","text":"We\u2019ve written some recipes that demonstrate how to solve common problems with Okio. Read through them to learn about how everything works together. Cut-and-paste these examples freely; that\u2019s what they\u2019re for.","title":"Recipes"},{"location":"#read-a-text-file-line-by-line-javakotlin","text":"Use Okio.source(File) to open a source stream to read a file. The returned Source interface is very small and has limited uses. Instead we wrap the source with a buffer. This has two benefits: It makes the API more powerful. Instead of the basic methods offered by Source , BufferedSource has dozens of methods to address most common problems concisely. It makes your program run faster. Buffering allows Okio to get more done with fewer I/O operations. Each Source that is opened needs to be closed. The code that opens the stream is responsible for making sure it is closed. Java Here we use Java\u2019s try blocks to close our sources automatically. public void readLines ( File file ) throws IOException { try ( Source fileSource = Okio . source ( file ); BufferedSource bufferedSource = Okio . buffer ( fileSource )) { while ( true ) { String line = bufferedSource . readUtf8Line (); if ( line == null ) break ; if ( line . contains ( \"square\" )) { System . out . println ( line ); } } } } Kotlin Note that static Okio methods become extension functions ( Okio.source(file) => file.source() ), and use is used to automatically close the streams: @Throws ( IOException :: class ) fun readLines ( file : File ) { file . source (). use { fileSource -> fileSource . buffer (). use { bufferedFileSource -> while ( true ) { val line = bufferedFileSource . readUtf8Line () ?: break if ( \"square\" in line ) { println ( line ) } } } } } The readUtf8Line() API reads all of the data until the next line delimiter \u2013 either \\n , \\r\\n , or the end of the file. It returns that data as a string, omitting the delimiter at the end. When it encounters empty lines the method will return an empty string. If there isn\u2019t any more data to read it will return null. The above program can be written more compactly by inlining the fileSource variable and by using a fancy for loop instead of a while : public void readLines ( File file ) throws IOException { try ( BufferedSource source = Okio . buffer ( Okio . source ( file ))) { for ( String line ; ( line = source . readUtf8Line ()) != null ; ) { if ( line . contains ( \"square\" )) { System . out . println ( line ); } } } } In Kotlin, we can wrap invocations of source.readUtf8Line() into the generateSequence builder to create a sequence of lines that will end once null is returned. Plus, transforming streams is easy thanks to the extension functions: @Throws ( IOException :: class ) fun readLines ( file : File ) { file . source (). buffer (). use { source -> generateSequence { source . readUtf8Line () } . filter { line -> \"square\" in line } . forEach ( :: println ) } } The readUtf8Line() method is suitable for parsing most files. For certain use-cases you may also consider readUtf8LineStrict() . It is similar but it requires that each line is terminated by \\n or \\r\\n . If it encounters the end of the file before that it will throw an EOFException . The strict variant also permits a byte limit to defend against malformed input. public void readLines ( File file ) throws IOException { try ( BufferedSource source = Okio . buffer ( Okio . source ( file ))) { while ( ! source . exhausted ()) { String line = source . readUtf8LineStrict ( 1024L ); if ( line . contains ( \"square\" )) { System . out . println ( line ); } } } } Here\u2019s a similar example written in Kotlin: @Throws ( IOException :: class ) fun readLines ( file : File ) { file . source (). buffer (). use { source -> while (! source . exhausted ()) { val line = source . readUtf8LineStrict ( 1024 ) if ( \"square\" in line ) { println ( line ) } } } }","title":"Read a text file line-by-line (Java/Kotlin)"},{"location":"#write-a-text-file-javakotlin","text":"Above we used a Source and a BufferedSource to read a file. To write, we use a Sink and a BufferedSink . The advantages of buffering are the same: a more capable API and better performance. public void writeEnv ( File file ) throws IOException { try ( Sink fileSink = Okio . sink ( file ); BufferedSink bufferedSink = Okio . buffer ( fileSink )) { for ( Map . Entry < String , String > entry : System . getenv (). entrySet ()) { bufferedSink . writeUtf8 ( entry . getKey ()); bufferedSink . writeUtf8 ( \"=\" ); bufferedSink . writeUtf8 ( entry . getValue ()); bufferedSink . writeUtf8 ( \"\\n\" ); } } } There isn\u2019t an API to write a line of input; instead we manually insert our own newline character. Most programs should hardcode \"\\n\" as the newline character. In rare situations you may use System.lineSeparator() instead of \"\\n\" : it returns \"\\r\\n\" on Windows and \"\\n\" everywhere else. We can write the above program more compactly by inlining the fileSink variable and by taking advantage of method chaining: Java public void writeEnv ( File file ) throws IOException { try ( BufferedSink sink = Okio . buffer ( Okio . sink ( file ))) { for ( Map . Entry < String , String > entry : System . getenv (). entrySet ()) { sink . writeUtf8 ( entry . getKey ()) . writeUtf8 ( \"=\" ) . writeUtf8 ( entry . getValue ()) . writeUtf8 ( \"\\n\" ); } } } Kotlin @Throws ( IOException :: class ) fun writeEnv ( file : File ) { file . sink (). buffer (). use { sink -> for (( key , value ) in System . getenv ()) { sink . writeUtf8 ( key ) sink . writeUtf8 ( \"=\" ) sink . writeUtf8 ( value ) sink . writeUtf8 ( \"\\n\" ) } } } In the above code we make four calls to writeUtf8() . Making four calls is more efficient than the code below because the VM doesn\u2019t have to create and garbage collect a temporary string. sink . writeUtf8 ( entry . getKey () + \"=\" + entry . getValue () + \"\\n\" ); // Slower!","title":"Write a text file (Java/Kotlin)"},{"location":"#utf-8-javakotlin","text":"In the above APIs you can see that Okio really likes UTF-8. Early computer systems suffered many incompatible character encodings: ISO-8859-1, ShiftJIS, ASCII, EBCDIC, etc. Writing software to support multiple character sets was awful and we didn\u2019t even have emoji! Today we\u2019re lucky that the world has standardized on UTF-8 everywhere, with some rare uses of other charsets in legacy systems. If you need another character set, readString() and writeString() are there for you. These methods require that you specify a character set. Otherwise you may accidentally create data that is only readable by the local computer. Most programs should use the UTF-8 methods only. When encoding strings you need to be mindful of the different ways that strings are represented and encoded. When a glyph has an accent or another adornment it may be represented as a single complex code point ( \u00e9 ) or as a simple code point ( e ) followed by its modifiers ( \u00b4 ). When the entire glyph is a single code point that\u2019s called NFC ; when it\u2019s multiple it\u2019s NFD . Though we use UTF-8 whenever we read or write strings in I/O, when they are in memory Java Strings use an obsolete character encoding called UTF-16. It is a bad encoding because it uses a 16-bit char for most characters, but some don\u2019t fit. In particular, most emoji use two Java chars. This is problematic because String.length() returns a surprising result: the number of UTF-16 chars and not the natural number of glyphs. Caf\u00e9 \ud83c\udf69 Cafe\u0301 \ud83c\udf69 Form NFC NFD Code Points c a f \u00e9 \u2423 \ud83c\udf69 c a f e \u00b4 \u2423 \ud83c\udf69 UTF-8 bytes 43 61 66 c3a9 20 f09f8da9 43 61 66 65 cc81 20 f09f8da9 String.codePointCount 6 7 String.length 7 8 Utf8.size 10 11 For the most part Okio lets you ignore these problems and focus on your data. But when you need them, there are convenient APIs for dealing with low-level UTF-8 strings. Use Utf8.size() to count the number of bytes required to encode a string as UTF-8 without actually encoding it. This is handy in length-prefixed encodings like protocol buffers. Use BufferedSource.readUtf8CodePoint() to read a single variable-length code point, and BufferedSink.writeUtf8CodePoint() to write one.","title":"UTF-8 (Java/Kotlin)"},{"location":"#golden-values-javakotlin","text":"Okio likes testing. The library itself is heavily tested, and it has features that are often helpful when testing application code. One pattern we\u2019ve found to be quite useful is \u201cgolden value\u201d testing. The goal of such tests is to confirm that data encoded with earlier versions of a program can safely be decoded by the current program. We\u2019ll illustrate this by encoding a value using Java Serialization. Though we must disclaim that Java Serialization is an awful encoding system and most programs should prefer other formats like JSON or protobuf! In any case, here\u2019s a method that takes an object, serializes it, and returns the result as a ByteString : Java private ByteString serialize ( Object o ) throws IOException { Buffer buffer = new Buffer (); try ( ObjectOutputStream objectOut = new ObjectOutputStream ( buffer . outputStream ())) { objectOut . writeObject ( o ); } return buffer . readByteString (); } Kotlin @Throws ( IOException :: class ) private fun serialize ( o : Any ?): ByteString { val buffer = Buffer () ObjectOutputStream ( buffer . outputStream ()). use { objectOut -> objectOut . writeObject ( o ) } return buffer . readByteString () } There\u2019s a lot going on here. We create a buffer as a holding space for our serialized data. It\u2019s a convenient replacement for ByteArrayOutputStream . We ask the buffer for its output stream. Writes to a buffer or its output stream always append data to the end of the buffer. We create an ObjectOutputStream (the encoding API for Java serialization) and write our object. The try block takes care of closing the stream for us. Note that closing a buffer has no effect. Finally we read a byte string from the buffer. The readByteString() method allows us to specify how many bytes to read; here we don\u2019t specify a count in order to read the entire thing. Reads from a buffer always consume data from the front of the buffer. With our serialize() method handy we are ready to compute and print a golden value. Java Point point = new Point ( 8.0 , 15.0 ); ByteString pointBytes = serialize ( point ); System . out . println ( pointBytes . base64 ()); Kotlin val point = Point ( 8.0 , 15.0 ) val pointBytes = serialize ( point ) println ( pointBytes . base64 ()) We print the ByteString as base64 because it\u2019s a compact format that\u2019s suitable for embedding in a test case. The program prints this: rO0ABXNyAB5va2lvLnNhbXBsZXMuR29sZGVuVmFsdWUkUG9pbnTdUW8rMji1IwIAAkQAAXhEAAF5eHBAIAAAAAAAAEAuAAAAAAAA That\u2019s our golden value! We can embed it in our test case using base64 again to convert it back into a ByteString : Java ByteString goldenBytes = ByteString . decodeBase64 ( \"rO0ABXNyAB5va2lvLnNhbXBsZ\" + \"XMuR29sZGVuVmFsdWUkUG9pbnTdUW8rMji1IwIAAkQAAXhEAAF5eHBAIAAAAAAAAEAuA\" + \"AAAAAAA\" ); Kotlin val goldenBytes = ( \"rO0ABXNyACRva2lvLnNhbXBsZXMuS290bGluR29sZGVuVmFsdWUkUG9pbnRF9yaY7cJ9EwIAA\" + \"kQAAXhEAAF5eHBAIAAAAAAAAEAuAAAAAAAA\" ). decodeBase64 () The next step is to deserialize the ByteString back into our value class. This method reverses the serialize() method above: we append a byte string to a buffer then consume it using an ObjectInputStream : Java private Object deserialize ( ByteString byteString ) throws IOException , ClassNotFoundException { Buffer buffer = new Buffer (); buffer . write ( byteString ); try ( ObjectInputStream objectIn = new ObjectInputStream ( buffer . inputStream ())) { return objectIn . readObject (); } } Kotlin @Throws ( IOException :: class , ClassNotFoundException :: class ) private fun deserialize ( byteString : ByteString ): Any ? { val buffer = Buffer () buffer . write ( byteString ) ObjectInputStream ( buffer . inputStream ()). use { objectIn -> return objectIn . readObject () } } Now we can test the decoder against the golden value: Java ByteString goldenBytes = ByteString . decodeBase64 ( \"rO0ABXNyAB5va2lvLnNhbXBsZ\" + \"XMuR29sZGVuVmFsdWUkUG9pbnTdUW8rMji1IwIAAkQAAXhEAAF5eHBAIAAAAAAAAEAuA\" + \"AAAAAAA\" ); Point decoded = ( Point ) deserialize ( goldenBytes ); assertEquals ( new Point ( 8.0 , 15.0 ), decoded ); Kotlin val goldenBytes = ( \"rO0ABXNyACRva2lvLnNhbXBsZXMuS290bGluR29sZGVuVmFsdWUkUG9pbnRF9yaY7cJ9EwIAA\" + \"kQAAXhEAAF5eHBAIAAAAAAAAEAuAAAAAAAA\" ). decodeBase64 () !! val decoded = deserialize ( goldenBytes ) as Point assertEquals ( point , decoded ) With this test we can change the serialization of the Point class without breaking compatibility.","title":"Golden Values (Java/Kotlin)"},{"location":"#write-a-binary-file-javakotlin","text":"Encoding a binary file is not unlike encoding a text file. Okio uses the same BufferedSink and BufferedSource bytes for both. This is handy for binary formats that include both byte and character data. Writing binary data is more hazardous than text because if you make a mistake it is often quite difficult to diagnose. Avoid such mistakes by being careful around these traps: The width of each field. This is the number of bytes used. Okio doesn\u2019t include a mechanism to emit partial bytes. If you need that, you\u2019ll need to do your own bit shifting and masking before writing. The endianness of each field. All fields that have more than one byte have endianness : whether the bytes are ordered most-significant to least (big endian) or least-significant to most (little endian). Okio uses the Le suffix for little-endian methods; methods without a suffix are big-endian. Signed vs. Unsigned. Java doesn\u2019t have unsigned primitive types (except for char !) so coping with this is often something that happens at the application layer. To make this a little easier Okio accepts int types for writeByte() and writeShort() . You can pass an \u201cunsigned\u201d byte like 255 and Okio will do the right thing. Method Width Endianness Value Encoded Value writeByte 1 3 03 writeShort 2 big 3 00 03 writeInt 4 big 3 00 00 00 03 writeLong 8 big 3 00 00 00 00 00 00 00 03 writeShortLe 2 little 3 03 00 writeIntLe 4 little 3 03 00 00 00 writeLongLe 8 little 3 03 00 00 00 00 00 00 00 writeByte 1 Byte.MAX_VALUE 7f writeShort 2 big Short.MAX_VALUE 7f ff writeInt 4 big Int.MAX_VALUE 7f ff ff ff writeLong 8 big Long.MAX_VALUE 7f ff ff ff ff ff ff ff writeShortLe 2 little Short.MAX_VALUE ff 7f writeIntLe 4 little Int.MAX_VALUE ff ff ff 7f writeLongLe 8 little Long.MAX_VALUE ff ff ff ff ff ff ff 7f This code encodes a bitmap following the BMP file format . Java void encode ( Bitmap bitmap , BufferedSink sink ) throws IOException { int height = bitmap . height (); int width = bitmap . width (); int bytesPerPixel = 3 ; int rowByteCountWithoutPadding = ( bytesPerPixel * width ); int rowByteCount = (( rowByteCountWithoutPadding + 3 ) / 4 ) * 4 ; int pixelDataSize = rowByteCount * height ; int bmpHeaderSize = 14 ; int dibHeaderSize = 40 ; // BMP Header sink . writeUtf8 ( \"BM\" ); // ID. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize + pixelDataSize ); // File size. sink . writeShortLe ( 0 ); // Unused. sink . writeShortLe ( 0 ); // Unused. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize ); // Offset of pixel data. // DIB Header sink . writeIntLe ( dibHeaderSize ); sink . writeIntLe ( width ); sink . writeIntLe ( height ); sink . writeShortLe ( 1 ); // Color plane count. sink . writeShortLe ( bytesPerPixel * Byte . SIZE ); sink . writeIntLe ( 0 ); // No compression. sink . writeIntLe ( 16 ); // Size of bitmap data including padding. sink . writeIntLe ( 2835 ); // Horizontal print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 2835 ); // Vertical print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 0 ); // Palette color count. sink . writeIntLe ( 0 ); // 0 important colors. // Pixel data. for ( int y = height - 1 ; y >= 0 ; y -- ) { for ( int x = 0 ; x < width ; x ++ ) { sink . writeByte ( bitmap . blue ( x , y )); sink . writeByte ( bitmap . green ( x , y )); sink . writeByte ( bitmap . red ( x , y )); } // Padding for 4-byte alignment. for ( int p = rowByteCountWithoutPadding ; p < rowByteCount ; p ++ ) { sink . writeByte ( 0 ); } } } Kotlin @Throws ( IOException :: class ) fun encode ( bitmap : Bitmap , sink : BufferedSink ) { val height = bitmap . height val width = bitmap . width val bytesPerPixel = 3 val rowByteCountWithoutPadding = bytesPerPixel * width val rowByteCount = ( rowByteCountWithoutPadding + 3 ) / 4 * 4 val pixelDataSize = rowByteCount * height val bmpHeaderSize = 14 val dibHeaderSize = 40 // BMP Header sink . writeUtf8 ( \"BM\" ) // ID. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize + pixelDataSize ) // File size. sink . writeShortLe ( 0 ) // Unused. sink . writeShortLe ( 0 ) // Unused. sink . writeIntLe ( bmpHeaderSize + dibHeaderSize ) // Offset of pixel data. // DIB Header sink . writeIntLe ( dibHeaderSize ) sink . writeIntLe ( width ) sink . writeIntLe ( height ) sink . writeShortLe ( 1 ) // Color plane count. sink . writeShortLe ( bytesPerPixel * Byte . SIZE_BITS ) sink . writeIntLe ( 0 ) // No compression. sink . writeIntLe ( 16 ) // Size of bitmap data including padding. sink . writeIntLe ( 2835 ) // Horizontal print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 2835 ) // Vertical print resolution in pixels/meter. (72 dpi). sink . writeIntLe ( 0 ) // Palette color count. sink . writeIntLe ( 0 ) // 0 important colors. // Pixel data. for ( y in height - 1 downTo 0 ) { for ( x in 0 until width ) { sink . writeByte ( bitmap . blue ( x , y )) sink . writeByte ( bitmap . green ( x , y )) sink . writeByte ( bitmap . red ( x , y )) } // Padding for 4-byte alignment. for ( p in rowByteCountWithoutPadding until rowByteCount ) { sink . writeByte ( 0 ) } } } The trickiest part of this program is the format\u2019s required padding. The BMP format expects each row to begin on a 4-byte boundary so it is necessary to add zeros to maintain the alignment. Encoding other binary formats is usually quite similar. Some tips: Write tests with golden values! Confirming that your program emits the expected result can make debugging easier. Use Utf8.size() to compute the number of bytes of an encoded string. This is essential for length-prefixed formats. Use Float.floatToIntBits() and Double.doubleToLongBits() to encode floating point values.","title":"Write a binary file (Java/Kotlin)"},{"location":"#communicate-on-a-socket-javakotlin","text":"Sending and receiving data over the network is a bit like writing and reading files. We use BufferedSink to encode output and BufferedSource to decode input. Like files, network protocols can be text, binary, or a mix of both. But there are also some substantial differences between the network and the filesystem. With a file you\u2019re either reading or writing but with the network you can do both! Some protocols handle this by taking turns: write a request, read a response, repeat. You can implement this kind of protocol with a single thread. In other protocols you may read and write simultaneously. Typically you\u2019ll want one dedicated thread for reading. For writing you can use either a dedicated thread or use synchronized so that multiple threads can share a sink. Okio\u2019s streams are not safe for concurrent use. Sinks buffer outbound data to minimize I/O operations. This is efficient but it means you must manually call flush() to transmit data. Typically message-oriented protocols flush after each message. Note that Okio will automatically flush when the buffered data exceeds some threshold. This is intended to save memory and you shouldn\u2019t rely on it for interactive protocols. Okio builds on java.io.Socket for connectivity. Create your socket as a server or as a client, then use Okio.source(Socket) to read and Okio.sink(Socket) to write. These APIs also work with SSLSocket . You should use SSL unless you have a very good reason not to! Cancel a socket from any thread by calling Socket.close() ; this will cause its sources and sinks to immediately fail with an IOException . You can also configure timeouts for all socket operations. You don\u2019t need a reference to the socket to adjust timeouts: Source and Sink expose timeouts directly. This API works even if the streams are decorated. As a complete example of networking with Okio we wrote a basic SOCKS proxy server. Some highlights: Java Socket fromSocket = ... BufferedSource fromSource = Okio . buffer ( Okio . source ( fromSocket )); BufferedSink fromSink = Okio . buffer ( Okio . sink ( fromSocket )); Kotlin val fromSocket : Socket = ... val fromSource = fromSocket . source (). buffer () val fromSink = fromSocket . sink (). buffer () Creating sources and sinks for sockets is the same as creating them for files. Once you create a Source or Sink for a socket you must not use its InputStream or OutputStream , respectively. Java Buffer buffer = new Buffer (); for ( long byteCount ; ( byteCount = source . read ( buffer , 8192L )) != - 1 ; ) { sink . write ( buffer , byteCount ); sink . flush (); } Kotlin val buffer = Buffer () var byteCount : Long while ( source . read ( buffer , 8192L ). also { byteCount = it } != - 1L ) { sink . write ( buffer , byteCount ) sink . flush () } The above loop copies data from the source to the sink, flushing after each read. If we didn\u2019t need the flushing we could replace this loop with a single call to BufferedSink.writeAll(Source) . The 8192 argument to read() is the maximum number of bytes to read before returning. We could have passed any value here, but we like 8 KiB because that\u2019s the largest value Okio can do in a single system call. Most of the time application code doesn\u2019t need to deal with such limits! Java int addressType = fromSource . readByte () & 0xff ; int port = fromSource . readShort () & 0xffff ; Kotlin val addressType = fromSource . readByte (). toInt () and 0 xff val port = fromSource . readShort (). toInt () and 0 xffff Okio uses signed types like byte and short , but often protocols want unsigned values. The bitwise & operator is Java\u2019s preferred idiom to convert a signed value into an unsigned value. Here\u2019s a cheat sheet for bytes, shorts, and ints: Type Signed Range Unsigned Range Signed to Unsigned byte -128..127 0..255 int u = s & 0xff; short -32,768..32,767 0..65,535 int u = s & 0xffff; int -2,147,483,648..2,147,483,647 0..4,294,967,295 long u = s & 0xffffffffL; Java has no primitive type that can represent unsigned longs.","title":"Communicate on a Socket (Java/Kotlin)"},{"location":"#hashing-javakotlin","text":"We\u2019re bombarded by hashing in our lives as Java programmers. Early on we\u2019re introduced to the hashCode() method, something we know we need to override otherwise unforeseen bad things happen. Later we\u2019re shown LinkedHashMap and its friends. These build on that hashCode() method to organize data for fast retrieval. Elsewhere we have cryptographic hash functions. These get used all over the place. HTTPS certificates, Git commits, BitTorrent integrity checking, and Blockchain blocks all use cryptographic hashes. Good use of hashes can improve the performance, privacy, security, and simplicity of an application. Each cryptographic hash function accepts a variable-length stream of input bytes and produces a fixed-length byte string value called the \u201chash\u201d. Hash functions have these important qualities: Deterministic: each input always produces the same output. Uniform: each output byte string is equally likely. It is very difficult to find or create pairs of different inputs that yield the same output. This is called a \u201ccollision\u201d. Non-reversible: knowing an output doesn\u2019t help you to find the input. Note that if you know some possible inputs you can hash them to see if their hashes match. Well-known: the hash is implemented everywhere and rigorously understood. Good hash functions are very cheap to compute (dozens of microseconds) and expensive to reverse (quintillions of millenia). Steady advances in computing and mathematics have caused once-great hash functions to become inexpensive to reverse. When choosing a hash function, beware that not all are created equal! Okio supports these well-known cryptographic hash functions: MD5 : a 128-bit (16 byte) cryptographic hash. It is both insecure and obsolete because it is inexpensive to reverse! This hash is offered because it is popular and convenient for use in legacy systems that are not security-sensitive. SHA-1 : a 160-bit (20 byte) cryptographic hash. It was recently demonstrated that it is feasible to create SHA-1 collisions. Consider upgrading from SHA-1 to SHA-256. SHA-256 : a 256-bit (32 byte) cryptographic hash. SHA-256 is widely understood and expensive to reverse. This is the hash most systems should use. SHA-512 : a 512-bit (64 byte) cryptographic hash. It is expensive to reverse. Each hash creates a ByteString of the specified length. Use hex() to get the conventional human-readable form. Or leave it as a ByteString because that\u2019s a convenient model type! Okio can produce cryptographic hashes from byte strings: Java ByteString byteString = readByteString ( new File ( \"README.md\" )); System . out . println ( \" md5: \" + byteString . md5 (). hex ()); System . out . println ( \" sha1: \" + byteString . sha1 (). hex ()); System . out . println ( \"sha256: \" + byteString . sha256 (). hex ()); System . out . println ( \"sha512: \" + byteString . sha512 (). hex ()); Kotlin val byteString = readByteString ( File ( \"README.md\" )) println ( \" md5: \" + byteString . md5 (). hex ()) println ( \" sha1: \" + byteString . sha1 (). hex ()) println ( \" sha256: \" + byteString . sha256 (). hex ()) println ( \" sha512: \" + byteString . sha512 (). hex ()) From buffers: Java Buffer buffer = readBuffer ( new File ( \"README.md\" )); System . out . println ( \" md5: \" + buffer . md5 (). hex ()); System . out . println ( \" sha1: \" + buffer . sha1 (). hex ()); System . out . println ( \"sha256: \" + buffer . sha256 (). hex ()); System . out . println ( \"sha512: \" + buffer . sha512 (). hex ()); Kotlin val buffer = readBuffer ( File ( \"README.md\" )) println ( \" md5: \" + buffer . md5 (). hex ()) println ( \" sha1: \" + buffer . sha1 (). hex ()) println ( \" sha256: \" + buffer . sha256 (). hex ()) println ( \" sha512: \" + buffer . sha512 (). hex ()) While streaming from a source: Java try ( HashingSink hashingSink = HashingSink . sha256 ( Okio . blackhole ()); BufferedSource source = Okio . buffer ( Okio . source ( file ))) { source . readAll ( hashingSink ); System . out . println ( \"sha256: \" + hashingSink . hash (). hex ()); } Kotlin sha256 ( blackholeSink ()). use { hashingSink -> file . source (). buffer (). use { source -> source . readAll ( hashingSink ) println ( \" sha256: \" + hashingSink . hash . hex ()) } } While streaming to a sink: Java try ( HashingSink hashingSink = HashingSink . sha256 ( Okio . blackhole ()); BufferedSink sink = Okio . buffer ( hashingSink ); Source source = Okio . source ( file )) { sink . writeAll ( source ); sink . close (); // Emit anything buffered. System . out . println ( \"sha256: \" + hashingSink . hash (). hex ()); } Kotlin sha256 ( blackholeSink ()). use { hashingSink -> hashingSink . buffer (). use { sink -> file . source (). use { source -> sink . writeAll ( source ) sink . close () // Emit anything buffered. println ( \" sha256: \" + hashingSink . hash . hex ()) } } } Okio also supports HMAC (Hash Message Authentication Code) which combines a secret and a hash. Applications use HMAC for data integrity and authentication. Java ByteString secret = ByteString . decodeHex ( \"7065616e7574627574746572\" ); System . out . println ( \"hmacSha256: \" + byteString . hmacSha256 ( secret ). hex ()); Kotlin val secret = \"7065616e7574627574746572\" . decodeHex () println ( \"hmacSha256: \" + byteString . hmacSha256 ( secret ). hex ()) As with hashing, you can generate an HMAC from a ByteString , Buffer , HashingSource , and HashingSink . Note that Okio doesn\u2019t implement HMAC for MD5. Okio uses Java\u2019s java.security.MessageDigest for cryptographic hashes and javax.crypto.Mac for HMAC.","title":"Hashing (Java/Kotlin)"},{"location":"#encryption-and-decryption","text":"Use Okio.cipherSink(Sink, Cipher) or Okio.cipherSource(Source, Cipher) to encrypt or decrypt a stream using a block cipher. Callers are responsible for the initialization of the encryption or decryption cipher with the chosen algorithm, the key, and algorithm-specific additional parameters like the initialization vector. The following example shows a typical usage with AES encryption, in which key and iv parameters should both be 16 bytes long. void encryptAes ( ByteString bytes , File file , byte [] key , byte [] iv ) throws GeneralSecurityException , IOException { Cipher cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ); cipher . init ( Cipher . ENCRYPT_MODE , new SecretKeySpec ( key , \"AES\" ), new IvParameterSpec ( iv )); try ( BufferedSink sink = Okio . buffer ( Okio . cipherSink ( Okio . sink ( file ), cipher ))) { sink . write ( bytes ); } } ByteString decryptAesToByteString ( File file , byte [] key , byte [] iv ) throws GeneralSecurityException , IOException { Cipher cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ); cipher . init ( Cipher . DECRYPT_MODE , new SecretKeySpec ( key , \"AES\" ), new IvParameterSpec ( iv )); try ( BufferedSource source = Okio . buffer ( Okio . cipherSource ( Okio . source ( file ), cipher ))) { return source . readByteString (); } } In Kotlin, these encryption and decryption methods are extensions on Cipher : fun encryptAes ( bytes : ByteString , file : File , key : ByteArray , iv : ByteArray ) { val cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ) cipher . init ( Cipher . ENCRYPT_MODE , SecretKeySpec ( key , \"AES\" ), IvParameterSpec ( iv )) val cipherSink = file . sink (). cipherSink ( cipher ) cipherSink . buffer (). use { it . write ( bytes ) } } fun decryptAesToByteString ( file : File , key : ByteArray , iv : ByteArray ): ByteString { val cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ) cipher . init ( Cipher . DECRYPT_MODE , SecretKeySpec ( key , \"AES\" ), IvParameterSpec ( iv )) val cipherSource = file . source (). cipherSource ( cipher ) return cipherSource . buffer (). use { it . readByteString () } }","title":"Encryption and Decryption"},{"location":"#releases","text":"Our change log has release history. implementation ( \"com.squareup.okio:okio:2.9.0\" ) Snapshot builds are also available repositories { maven { url = uri ( \"https://oss.sonatype.org/content/repositories/snapshots/\" ) } } dependencies { implementation ( \"com.squareup.okio:okio:2.9.0\" ) }","title":"Releases"},{"location":"#r8-proguard","text":"If you are using R8 or ProGuard add the options from this file .","title":"R8 / ProGuard"},{"location":"#license","text":"Copyright 2013 Square, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"changelog/","text":"Change Log \u00b6 Version 2.9.0 \u00b6 2020-10-04 Fix: Don\u2019t corrupt the Buffer when writing a slice of a segmented ByteString . We had a severe bug where ByteString instances created with snapshot() and readByteString() incorrectly adjusted the buffer\u2019s size by their full length, not the length of the slice. This would have caused buffer reads to crash! We do not believe data was silently corrupted. New: CipherSink and CipherSource . Use these with javax.crypto.Cipher to encrypt and decrypt streams of data. This is a low-level encryption API; most applications should use higher-level APIs like TLS when available. New: Promote hash functions md5 , sha1() , sha512() , and sha256() to common Kotlin. These are currently only available on ByteString , multiplatform support for HashingSource , HashingSink , and Buffer should come in a follow-up release. We wrote and optimized our own implementations of these hash functions in Kotlin. On JVM and Android platforms Okio still uses the platform\u2019s built-in hash functions. New: Support OSGi metadata. Upgrade: Kotlin 1.4.10 . Version 2.8.0 \u00b6 2020-08-17 New: Upgrade to Kotlin 1.4.0. Version 2.7.0 \u00b6 2020-07-07 New: Pipe.cancel() causes in-progress and future reads and writes on the pipe to immediately fail with an IOException . The streams may still be canceled normally. New: Enlarge Okio\u2019s internal segment pool from a fixed 64 KiB total to 64 KiB per processor. For example, on an Intel i9 8-core/16-thread machine the segment pool now uses up to 1 MiB of memory. New: Migrate from synchronized to lock-free when accessing the segment pool. Combined with the change above we saw throughput increase 3x on a synthetic benchmark designed to create contention. Version 2.6.0 \u00b6 2020-04-22 New: InflaterSource.readOrInflate() is like InflaterSource.read() , except it will return 0 if consuming deflated bytes from the underlying stream did not produce new inflated bytes. Version 2.5.0 \u00b6 2020-03-20 New: Upgrade to Kotlin 1.3.70. Version 2.4.3 \u00b6 2019-12-20 New: Upgrade to Kotlin 1.3.61. Version 2.4.2 \u00b6 2019-12-11 Fix: Don\u2019t crash when an InputStream source is exhausted exactly at a buffer segment boundary. We had a bug where a sequence of reads could violate a buffer\u2019s invariants, and this could result in a crash when subsequent reads encountered an unexpected empty segment. Version 1.17.5 \u00b6 2019-12-11 Fix: Don\u2019t crash when an InputStream source is exhausted exactly at a buffer segment boundary. We had a bug where a sequence of reads could violate a buffer\u2019s invariants, and this could result in a crash when subsequent reads encountered an unexpected empty segment. Version 2.4.1 \u00b6 2019-10-04 Fix: Don\u2019t cache hash code and UTF-8 string in ByteString on Kotlin/Native which prevented freezing. Version 2.4.0 \u00b6 2019-08-26 New: Upgrade to Kotlin 1.3.50. Version 2.3.0 \u00b6 2019-07-29 This release changes our build from Kotlin-JVM to Kotlin-multiplatform (which includes JVM). Both native and JavaScript platforms are unstable preview releases and subject to backwards-incompatible changes in forthcoming releases. To try Okio in a multiplatform project use this Maven coordinate: api ( ' com . squareup . okio : okio - multiplatform : 2.3 . 0 ' ) You\u2019ll also need to enable Gradle metadata in your project\u2019s settings. The artifact name for JVM projects has not changed. New: Upgrade to Kotlin 1.3.40. Fix: Use Gradle api instead of implementation for the kotlin-stdlib dependency. Fix: Don\u2019t block unless strictly necessary in BufferedSource.peek() . Version 1.17.4 \u00b6 2019-04-29 Fix: Don\u2019t block unless strictly necessary in BufferedSource.peek() . Version 2.2.2 \u00b6 2019-01-28 Fix: Make Pipe.fold() close the underlying sink when necessary. Version 1.17.3 \u00b6 2019-01-28 Fix: Make Pipe.fold() close the underlying sink when necessary. Version 1.17.2 \u00b6 2019-01-17 Fix: Make Pipe.fold() flush the underlying sink. Version 2.2.1 \u00b6 2019-01-17 Fix: Make Pipe.fold() flush the underlying sink. Version 2.2.0 \u00b6 2019-01-16 New: Throttler limits sources and sinks to a maximum desired throughput. Multiple sources and sinks can be attached to the same throttler and their combined throughput will not exceed the desired throughput. Multiple throttlers can also be used on the same source or sink and they will all be honored. New: Pipe.fold() replaces the actively-readable Source with a passively-writable Sink . This can be used to forward one sink to a target that is initially undetermined. New: Optimize performance of ByteStrings created with Buffer.snapshot() . Version 1.17.1 \u00b6 2019-01-16 Fix: Make the newly-backported Pipe.fold() public. Version 1.17.0 \u00b6 2019-01-16 New: Backport Pipe.fold() to Okio 1.x. Version 1.16.0 \u00b6 2018-10-08 New: Backport BufferedSource.peek() and BufferedSource.getBuffer() to Okio 1.x. Fix: Enforce timeouts when closing AsyncTimeout sources. Version 2.1.0 \u00b6 2018-09-22 New: BufferedSource.peek() returns another BufferedSource that reads ahead on the current source. Use this to process the same data multiple times. New: Deprecate BufferedSource.buffer() , replacing it with either BufferedSource.getBuffer() (in Java) or BufferedSource.buffer (in Kotlin). We have done likewise for BufferedSink . When we introduced the new extension method Source.buffer() in Okio 2.0 we inadvertently collided with an existing method. This fixes that. New: Improve performance of Buffer.writeUtf8() . This comes alongside initial implementation of UTF-8 encoding and decoding in JavaScript which uses XOR masks for great performance. Version 2.0.0 \u00b6 2018-08-27 This release commits to a stable 2.0 API. Read the 2.0.0-RC1 changes for advice on upgrading from 1.x to 2.x. We\u2019ve also added APIs to ease migration for Kotlin users. They use Kotlin\u2019s @Deprecated annotation to help you change call sites from the 1.x style to the 2.x style. Version 2.0.0-RC1 \u00b6 2018-07-26 Okio 2 is a major release that upgrades the library\u2019s implementation language from Java to Kotlin. Okio 2.x is binary-compatible with Okio 1.x and does not change any behavior. Classes and .jar files compiled against 1.x can be used with 2.x without recompiling. Okio 2.x is .java source compatible with Okio 1.x in all but one corner case. In Okio 1.x Buffer would throw an unchecked IllegalStateException when attempting to read more bytes than available. Okio 2.x now throws a checked EOFException in this case. This is now consistent with the behavior of its BufferedSource interface. Java callers that don\u2019t already catch IOException will now need to. Okio 2.x is .kt source-incompatible with Okio 1.x. This release adopts Kotlin idioms where they are available. Java Kotlin Idiom Buffer.getByte() operator fun Buffer.get() operator function Buffer.size() val Buffer.size val ByteString.decodeBase64(String) fun String.decodeBase64() extension function ByteString.decodeHex(String) fun String.decodeHex() extension function ByteString.encodeString(String, Charset) fun String.encode(Charset) extension function ByteString.encodeUtf8(String) fun String.encodeUtf8() extension function ByteString.getByte() operator fun ByteString.get() operator function ByteString.of(ByteBuffer) fun ByteBuffer.toByteString() extension function ByteString.of(byte[], int, int) fun ByteArray.toByteString() extension function ByteString.read(InputStream, int) fun InputStream.readByteString(Int) extension function ByteString.size() val ByteString.size val DeflaterSink(Sink) fun Sink.deflater() extension function ForwardingSink.delegate() val ForwardingSink.delegate val ForwardingSource.delegate() val ForwardingSource.delegate val GzipSink(Sink, Deflater) fun Sink.gzip() extension function GzipSink.deflater() val GzipSink.deflater val GzipSource(Source) fun Source.gzip() extension function HashingSink.hash() val HashingSink.hash val HashingSource.hash() val HashingSource.hash val InflaterSink(Source) fun Source.inflater() extension function Okio.appendingSink(File) fun File.appendingSink() extension function Okio.blackhole() fun blackholeSink() top level function Okio.buffer(Sink) fun Sink.buffer() extension function Okio.buffer(Source) fun Source.buffer() extension function Okio.sink(File) fun File.sink() extension function Okio.sink(OutputStream) fun OutputStream.sink() extension function Okio.sink(Path) fun Path.sink() extension function Okio.sink(Socket) fun Socket.sink() extension function Okio.source(File) fun File.source() extension function Okio.source(InputStream) fun InputStream.source() extension function Okio.source(Path) fun Path.source() extension function Okio.source(Socket) fun Socket.source() extension function Pipe.sink() val Pipe.sink val Pipe.source() val Pipe.source val Utf8.size(String) fun String.utf8Size() extension function Okio 2.x has similar performance to Okio 1.x. We benchmarked both versions to find potential performance regressions. We found one regression and fixed it: we were using == instead of === . Other changes in this release: New: Add a dependency on kotlin-stdlib. Okio\u2019s transitive dependencies grow from none in 1.x to three in 2.x. These are kotlin-stdlib (939 KiB), kotlin-stdlib-common (104 KiB), and JetBrains\u2019 annotations (17 KiB). New: Change Okio to build with Gradle instead of Maven. Version 1.15.0 \u00b6 2018-07-18 New: Trie-based Buffer.select() . This improves performance when selecting among large lists of options. Fix: Retain interrupted state when throwing InterruptedIOException . Version 1.14.0 \u00b6 2018-02-11 New: Buffer.UnsafeCursor provides direct access to Okio internals. This API is like Okio\u2019s version of Java reflection: it\u2019s a very powerful API that can be used for great things and dangerous things alike. The documentation is extensive and anyone using it should review it carefully before proceeding! New: Change BufferedSource to implement java.nio.ReadableByteChannel and BufferedSink to implement java.nio.WritableByteChannel . Now it\u2019s a little easier to interop between Okio and NIO. New: Automatic module name of okio for use with the Java Platform Module System. New: Optimize Buffer.getByte() to search backwards when doing so will be more efficient. Fix: Honor the requested byte count in InflaterSource . Previously this class could return more bytes than requested. Fix: Improve a performance bug in AsyncTimeout.sink().write() . Version 1.13.0 \u00b6 2017-05-12 Okio now uses @Nullable to annotate all possibly-null values. We\u2019ve added a compile-time dependency on the JSR 305 annotations. This is a provided dependency and does not need to be included in your build configuration, .jar file, or .apk . We use @ParametersAreNonnullByDefault and all parameters and return types are never null unless explicitly annotated @Nullable . Warning: this release is source-incompatible for Kotlin users. Nullability was previously ambiguous and lenient but now the compiler will enforce strict null checks. Version 1.12.0 \u00b6 2017-04-11 Fix: Change Pipe\u2019s sink.flush() to not block. Previously closing a pipe\u2019s sink would block until the source had been exhausted. In practice this blocked the caller for no benefit. Fix: Change writeUtf8CodePoint() to emit ? for partial surrogates. The previous behavior was inconsistent: given a malformed string with a partial surrogate, writeUtf8() emitted ? but writeUtf8CodePoint() threw an IllegalArgumentException . Most applications will never encounter partial surrogates, but for those that do this behavior was unexpected. New: Allow length of readUtf8LineStrict() to be limited. New: Utf8.size() method to get the number of bytes required to encode a string as UTF-8. This may be useful for length-prefixed encodings. New: SHA-512 hash and HMAC APIs. Version 1.11.0 \u00b6 2016-10-11 Fix: The four-argument overload of Buffer.writeString() had a major bug where it didn\u2019t respect offsets if the specified charset was UTF-8. This was because our short-circuit optimization omitted necessary offset parameters. New: HMAC support in HashingSource , HashingSink , ByteString , and Buffer . This makes it easy to create a keyed-hash message authentication code (HMAC) wherever your data is. Unlike the other hashes, HMAC uses a ByteString secret key for authentication. New: ByteString.of(ByteBuffer) makes it easier to mix NIO with Okio. Version 1.10.0 \u00b6 2016-08-28 Fix: Support reading files larger than 2 GiB with GzipSource . Previously attempting to decompress such files would fail due to an overflow when validating the total length. Fix: Exit the watchdog thread after being idle for 60 seconds. This should make it possible for class unloaders to fully unload Okio. New: Okio.blackhole() returns a sink where all bytes written are discarded. This is Okio\u2019s equivalent of /dev/null . New: Encode a string with any charset using ByteString.encodeString() and decode strings in any charset using ByteString.string() . Most applications should prefer ByteString.encodeUtf8() and ByteString.utf8() unless it\u2019s necessary to support a legacy charset. New: GzipSink.deflater() makes it possible to configure the compression level. Version 1.9.0 \u00b6 2016-07-01 New: Pipe makes it easy to connect a producer thread to a consumer thread. Reads block until data is available to read. Writes block if the pipe\u2019s is full. Both sources and sinks support timeouts. New: BufferedSource.rangeEquals() makes it easy to compare a range in a stream to an expected value. This does the right thing: it blocks to load the data required return a definitive result. But it won\u2019t block unnecessarily. New: Timeout.waitUntilNotified() makes it possible to use nice timeout abstractions on Java\u2019s built-in wait/notify primitives. Fix: Don\u2019t return incorrect results when HashingSource does large reads. There was a bug where it wasn\u2019t traversing through the segments of the buffer being hashed. This means that HashingSource was returning incorrect answers for any writes that spanned multiple segment boundaries. Version 1.8.0 \u00b6 2016-05-02 New: BufferedSource.select(Options) API for reading one of a set of expected values. New: Make ByteString.toString() and Buffer.toString() friendlier. These methods return text if the byte string is valid UTF-8. New: APIs to match byte strings: indexOf() , startsWith() , and endsWith() . Version 1.7.0 \u00b6 2016-04-10 New: Change the segment size to 8 KiB. This has been reported to dramatically improve performance in some applications. New: md5() , sha1() , and sha256() methods on Buffer . Also add a sha1() method on ByteString for symmetry. New: HashingSource and HashingSink . These classes are Okio\u2019s equivalent to the JDK\u2019s DigestInputStream and DigestOutputStream . They offer convenient md5() , sha1() , and sha256() factory methods to avoid an impossible NoSuchAlgorithmException . New: ByteString.asByteBuffer() . Fix: Limit snapshot byte strings to requested size. Fix: Change write timeouts to have a maximum write size. Previously large writes could easly suffer timeouts because the entire write was subject to a single timeout. Fix: Recover from EBADF failures, which could be triggered by asynchronously closing a stream on older versions of Android. Fix: Don\u2019t share segments if doing so only saves a small copy. This should improve performance for all applications. Fix: Optimize BufferedSource.indexOfElement() and indexOf(ByteString) . Previously this method had a bug that caused it to be very slow on large buffers. Version 1.6.0 \u00b6 2015-08-25 New: BufferedSource.indexOf(ByteString) searches a source for the next occurrence of a byte string. Fix: Recover from unexpected AssertionError thrown on Android 4.2.2 and earlier when asynchronously closing a socket. Version 1.5.0 \u00b6 2015-06-19 Sockets streams now throw SocketTimeoutException . This builds on new extension point in AsyncTimeout to customize the exception when a timeout occurs. New: ByteString now implements Comparable . The comparison sorts bytes as unsigned: {@code ff} sorts after {@code 00}. Version 1.4.0 \u00b6 2015-05-16 Timeout exception changed. Previously Timeout.throwIfReached() would throw InterruptedIOException on thread interruption, and IOException if the deadline was reached. Now it throws InterruptedIOException in both cases. Fix: throw EOFException when attempting to read digits from an empty source. Previously this would crash with an unchecked exception. New: APIs to read and write UTF-8 code points without allocating strings. New: BufferedSink can now write substrings directly, potentially saving an allocation for some callers. New: ForwardingTimeout class. Version 1.3.0 \u00b6 2015-03-16 New: Read and write signed decimal and unsigned hexadecimal values in BufferedSource and BufferedSink . Unlike the alternatives, these methods don\u2019t do any memory allocations! New: Segment sharing. This improves the runtime of operations like Buffer.clone() and Buffer.copyTo() by sharing underlying segments between buffers. New: Buffer.snapshot() returns an immutable snapshot of a buffer as a ByteString . This builds on segment sharing so that snapshots are shallow, immutable copies. New: ByteString.rangeEquals() . New: ByteString.md5() and ByteString.sha256() . New: ByteString.base64Url() returns URL-safe Base64. The existing decoding method has been extended to support URL-safe Base64 input. New: ByteString.substring() returns a prefix, infix, or suffix. New: Sink now implements java.io.Flushable . Fix: Buffer.write(Source, long) now always writes fully. The previous behavior would return as soon as any data had been written; this was inconsistent with all other write() methods in the API. Fix: don\u2019t leak empty segments in DeflaterSink and InflaterSource. (This was unlikely to cause problems in practice.) Version 1.2.0 \u00b6 2014-12-30 Fix: Okio.buffer() always buffers for better predictability. Fix: Provide context when readUtf8LineStrict() throws. Fix: Buffers do not call through the Source on zero-byte writes. Version 1.1.0 \u00b6 2014-12-11 Do UTF-8 encoding natively for a performance increase, particularly on Android. New APIs: BufferedSink.emit() , BufferedSource.request() and BufferedSink.indexOfElement() . Fixed a performance bug in Buffer.indexOf() Version 1.0.1 \u00b6 2014-08-08 Added read(byte[]) , read(byte[], offset, byteCount) , and void readFully(byte[]) to BufferedSource . Refined declared checked exceptions on Buffer methods. Version 1.0.0 \u00b6 2014-05-23 Bumped release version. No other changes! Version 0.9.0 \u00b6 2014-05-03 Use 0 as a sentinel for no timeout. Make AsyncTimeout public. Remove checked exception from Buffer.readByteArray. Version 0.8.0 \u00b6 2014-04-24 Eagerly verify preconditions on public APIs. Quick return on Buffer instance equivalence. Add delegate types for Sink and Source. Small changes to the way deadlines are managed. Add append variant of Okio.sink for File. Methods to exhaust BufferedSource to byte[] and ByteString. Version 0.7.0 \u00b6 2014-04-18 Don\u2019t use getters in timeout. Use the watchdog to interrupt sockets that have reached deadlines. Add java.io and java.nio file source/sink helpers. Version 0.6.1 \u00b6 2014-04-17 Methods to read a buffered source fully in UTF-8 or supplied charset. API to read a byte[] directly. New methods to move all data from a source to a sink. Fix a bug on input stream exhaustion. Version 0.6.0 \u00b6 2014-04-15 Make ByteString serializable. New API: ByteString.of(byte[] data, int offset, int byteCount) New API: stream-based copy, write, and read helpers. Version 0.5.0 \u00b6 2014-04-08 Initial public release. Imported from OkHttp.","title":"Change Log"},{"location":"changelog/#change-log","text":"","title":"Change Log"},{"location":"changelog/#version-290","text":"2020-10-04 Fix: Don\u2019t corrupt the Buffer when writing a slice of a segmented ByteString . We had a severe bug where ByteString instances created with snapshot() and readByteString() incorrectly adjusted the buffer\u2019s size by their full length, not the length of the slice. This would have caused buffer reads to crash! We do not believe data was silently corrupted. New: CipherSink and CipherSource . Use these with javax.crypto.Cipher to encrypt and decrypt streams of data. This is a low-level encryption API; most applications should use higher-level APIs like TLS when available. New: Promote hash functions md5 , sha1() , sha512() , and sha256() to common Kotlin. These are currently only available on ByteString , multiplatform support for HashingSource , HashingSink , and Buffer should come in a follow-up release. We wrote and optimized our own implementations of these hash functions in Kotlin. On JVM and Android platforms Okio still uses the platform\u2019s built-in hash functions. New: Support OSGi metadata. Upgrade: Kotlin 1.4.10 .","title":"Version 2.9.0"},{"location":"changelog/#version-280","text":"2020-08-17 New: Upgrade to Kotlin 1.4.0.","title":"Version 2.8.0"},{"location":"changelog/#version-270","text":"2020-07-07 New: Pipe.cancel() causes in-progress and future reads and writes on the pipe to immediately fail with an IOException . The streams may still be canceled normally. New: Enlarge Okio\u2019s internal segment pool from a fixed 64 KiB total to 64 KiB per processor. For example, on an Intel i9 8-core/16-thread machine the segment pool now uses up to 1 MiB of memory. New: Migrate from synchronized to lock-free when accessing the segment pool. Combined with the change above we saw throughput increase 3x on a synthetic benchmark designed to create contention.","title":"Version 2.7.0"},{"location":"changelog/#version-260","text":"2020-04-22 New: InflaterSource.readOrInflate() is like InflaterSource.read() , except it will return 0 if consuming deflated bytes from the underlying stream did not produce new inflated bytes.","title":"Version 2.6.0"},{"location":"changelog/#version-250","text":"2020-03-20 New: Upgrade to Kotlin 1.3.70.","title":"Version 2.5.0"},{"location":"changelog/#version-243","text":"2019-12-20 New: Upgrade to Kotlin 1.3.61.","title":"Version 2.4.3"},{"location":"changelog/#version-242","text":"2019-12-11 Fix: Don\u2019t crash when an InputStream source is exhausted exactly at a buffer segment boundary. We had a bug where a sequence of reads could violate a buffer\u2019s invariants, and this could result in a crash when subsequent reads encountered an unexpected empty segment.","title":"Version 2.4.2"},{"location":"changelog/#version-1175","text":"2019-12-11 Fix: Don\u2019t crash when an InputStream source is exhausted exactly at a buffer segment boundary. We had a bug where a sequence of reads could violate a buffer\u2019s invariants, and this could result in a crash when subsequent reads encountered an unexpected empty segment.","title":"Version 1.17.5"},{"location":"changelog/#version-241","text":"2019-10-04 Fix: Don\u2019t cache hash code and UTF-8 string in ByteString on Kotlin/Native which prevented freezing.","title":"Version 2.4.1"},{"location":"changelog/#version-240","text":"2019-08-26 New: Upgrade to Kotlin 1.3.50.","title":"Version 2.4.0"},{"location":"changelog/#version-230","text":"2019-07-29 This release changes our build from Kotlin-JVM to Kotlin-multiplatform (which includes JVM). Both native and JavaScript platforms are unstable preview releases and subject to backwards-incompatible changes in forthcoming releases. To try Okio in a multiplatform project use this Maven coordinate: api ( ' com . squareup . okio : okio - multiplatform : 2.3 . 0 ' ) You\u2019ll also need to enable Gradle metadata in your project\u2019s settings. The artifact name for JVM projects has not changed. New: Upgrade to Kotlin 1.3.40. Fix: Use Gradle api instead of implementation for the kotlin-stdlib dependency. Fix: Don\u2019t block unless strictly necessary in BufferedSource.peek() .","title":"Version 2.3.0"},{"location":"changelog/#version-1174","text":"2019-04-29 Fix: Don\u2019t block unless strictly necessary in BufferedSource.peek() .","title":"Version 1.17.4"},{"location":"changelog/#version-222","text":"2019-01-28 Fix: Make Pipe.fold() close the underlying sink when necessary.","title":"Version 2.2.2"},{"location":"changelog/#version-1173","text":"2019-01-28 Fix: Make Pipe.fold() close the underlying sink when necessary.","title":"Version 1.17.3"},{"location":"changelog/#version-1172","text":"2019-01-17 Fix: Make Pipe.fold() flush the underlying sink.","title":"Version 1.17.2"},{"location":"changelog/#version-221","text":"2019-01-17 Fix: Make Pipe.fold() flush the underlying sink.","title":"Version 2.2.1"},{"location":"changelog/#version-220","text":"2019-01-16 New: Throttler limits sources and sinks to a maximum desired throughput. Multiple sources and sinks can be attached to the same throttler and their combined throughput will not exceed the desired throughput. Multiple throttlers can also be used on the same source or sink and they will all be honored. New: Pipe.fold() replaces the actively-readable Source with a passively-writable Sink . This can be used to forward one sink to a target that is initially undetermined. New: Optimize performance of ByteStrings created with Buffer.snapshot() .","title":"Version 2.2.0"},{"location":"changelog/#version-1171","text":"2019-01-16 Fix: Make the newly-backported Pipe.fold() public.","title":"Version 1.17.1"},{"location":"changelog/#version-1170","text":"2019-01-16 New: Backport Pipe.fold() to Okio 1.x.","title":"Version 1.17.0"},{"location":"changelog/#version-1160","text":"2018-10-08 New: Backport BufferedSource.peek() and BufferedSource.getBuffer() to Okio 1.x. Fix: Enforce timeouts when closing AsyncTimeout sources.","title":"Version 1.16.0"},{"location":"changelog/#version-210","text":"2018-09-22 New: BufferedSource.peek() returns another BufferedSource that reads ahead on the current source. Use this to process the same data multiple times. New: Deprecate BufferedSource.buffer() , replacing it with either BufferedSource.getBuffer() (in Java) or BufferedSource.buffer (in Kotlin). We have done likewise for BufferedSink . When we introduced the new extension method Source.buffer() in Okio 2.0 we inadvertently collided with an existing method. This fixes that. New: Improve performance of Buffer.writeUtf8() . This comes alongside initial implementation of UTF-8 encoding and decoding in JavaScript which uses XOR masks for great performance.","title":"Version 2.1.0"},{"location":"changelog/#version-200","text":"2018-08-27 This release commits to a stable 2.0 API. Read the 2.0.0-RC1 changes for advice on upgrading from 1.x to 2.x. We\u2019ve also added APIs to ease migration for Kotlin users. They use Kotlin\u2019s @Deprecated annotation to help you change call sites from the 1.x style to the 2.x style.","title":"Version 2.0.0"},{"location":"changelog/#version-200-rc1","text":"2018-07-26 Okio 2 is a major release that upgrades the library\u2019s implementation language from Java to Kotlin. Okio 2.x is binary-compatible with Okio 1.x and does not change any behavior. Classes and .jar files compiled against 1.x can be used with 2.x without recompiling. Okio 2.x is .java source compatible with Okio 1.x in all but one corner case. In Okio 1.x Buffer would throw an unchecked IllegalStateException when attempting to read more bytes than available. Okio 2.x now throws a checked EOFException in this case. This is now consistent with the behavior of its BufferedSource interface. Java callers that don\u2019t already catch IOException will now need to. Okio 2.x is .kt source-incompatible with Okio 1.x. This release adopts Kotlin idioms where they are available. Java Kotlin Idiom Buffer.getByte() operator fun Buffer.get() operator function Buffer.size() val Buffer.size val ByteString.decodeBase64(String) fun String.decodeBase64() extension function ByteString.decodeHex(String) fun String.decodeHex() extension function ByteString.encodeString(String, Charset) fun String.encode(Charset) extension function ByteString.encodeUtf8(String) fun String.encodeUtf8() extension function ByteString.getByte() operator fun ByteString.get() operator function ByteString.of(ByteBuffer) fun ByteBuffer.toByteString() extension function ByteString.of(byte[], int, int) fun ByteArray.toByteString() extension function ByteString.read(InputStream, int) fun InputStream.readByteString(Int) extension function ByteString.size() val ByteString.size val DeflaterSink(Sink) fun Sink.deflater() extension function ForwardingSink.delegate() val ForwardingSink.delegate val ForwardingSource.delegate() val ForwardingSource.delegate val GzipSink(Sink, Deflater) fun Sink.gzip() extension function GzipSink.deflater() val GzipSink.deflater val GzipSource(Source) fun Source.gzip() extension function HashingSink.hash() val HashingSink.hash val HashingSource.hash() val HashingSource.hash val InflaterSink(Source) fun Source.inflater() extension function Okio.appendingSink(File) fun File.appendingSink() extension function Okio.blackhole() fun blackholeSink() top level function Okio.buffer(Sink) fun Sink.buffer() extension function Okio.buffer(Source) fun Source.buffer() extension function Okio.sink(File) fun File.sink() extension function Okio.sink(OutputStream) fun OutputStream.sink() extension function Okio.sink(Path) fun Path.sink() extension function Okio.sink(Socket) fun Socket.sink() extension function Okio.source(File) fun File.source() extension function Okio.source(InputStream) fun InputStream.source() extension function Okio.source(Path) fun Path.source() extension function Okio.source(Socket) fun Socket.source() extension function Pipe.sink() val Pipe.sink val Pipe.source() val Pipe.source val Utf8.size(String) fun String.utf8Size() extension function Okio 2.x has similar performance to Okio 1.x. We benchmarked both versions to find potential performance regressions. We found one regression and fixed it: we were using == instead of === . Other changes in this release: New: Add a dependency on kotlin-stdlib. Okio\u2019s transitive dependencies grow from none in 1.x to three in 2.x. These are kotlin-stdlib (939 KiB), kotlin-stdlib-common (104 KiB), and JetBrains\u2019 annotations (17 KiB). New: Change Okio to build with Gradle instead of Maven.","title":"Version 2.0.0-RC1"},{"location":"changelog/#version-1150","text":"2018-07-18 New: Trie-based Buffer.select() . This improves performance when selecting among large lists of options. Fix: Retain interrupted state when throwing InterruptedIOException .","title":"Version 1.15.0"},{"location":"changelog/#version-1140","text":"2018-02-11 New: Buffer.UnsafeCursor provides direct access to Okio internals. This API is like Okio\u2019s version of Java reflection: it\u2019s a very powerful API that can be used for great things and dangerous things alike. The documentation is extensive and anyone using it should review it carefully before proceeding! New: Change BufferedSource to implement java.nio.ReadableByteChannel and BufferedSink to implement java.nio.WritableByteChannel . Now it\u2019s a little easier to interop between Okio and NIO. New: Automatic module name of okio for use with the Java Platform Module System. New: Optimize Buffer.getByte() to search backwards when doing so will be more efficient. Fix: Honor the requested byte count in InflaterSource . Previously this class could return more bytes than requested. Fix: Improve a performance bug in AsyncTimeout.sink().write() .","title":"Version 1.14.0"},{"location":"changelog/#version-1130","text":"2017-05-12 Okio now uses @Nullable to annotate all possibly-null values. We\u2019ve added a compile-time dependency on the JSR 305 annotations. This is a provided dependency and does not need to be included in your build configuration, .jar file, or .apk . We use @ParametersAreNonnullByDefault and all parameters and return types are never null unless explicitly annotated @Nullable . Warning: this release is source-incompatible for Kotlin users. Nullability was previously ambiguous and lenient but now the compiler will enforce strict null checks.","title":"Version 1.13.0"},{"location":"changelog/#version-1120","text":"2017-04-11 Fix: Change Pipe\u2019s sink.flush() to not block. Previously closing a pipe\u2019s sink would block until the source had been exhausted. In practice this blocked the caller for no benefit. Fix: Change writeUtf8CodePoint() to emit ? for partial surrogates. The previous behavior was inconsistent: given a malformed string with a partial surrogate, writeUtf8() emitted ? but writeUtf8CodePoint() threw an IllegalArgumentException . Most applications will never encounter partial surrogates, but for those that do this behavior was unexpected. New: Allow length of readUtf8LineStrict() to be limited. New: Utf8.size() method to get the number of bytes required to encode a string as UTF-8. This may be useful for length-prefixed encodings. New: SHA-512 hash and HMAC APIs.","title":"Version 1.12.0"},{"location":"changelog/#version-1110","text":"2016-10-11 Fix: The four-argument overload of Buffer.writeString() had a major bug where it didn\u2019t respect offsets if the specified charset was UTF-8. This was because our short-circuit optimization omitted necessary offset parameters. New: HMAC support in HashingSource , HashingSink , ByteString , and Buffer . This makes it easy to create a keyed-hash message authentication code (HMAC) wherever your data is. Unlike the other hashes, HMAC uses a ByteString secret key for authentication. New: ByteString.of(ByteBuffer) makes it easier to mix NIO with Okio.","title":"Version 1.11.0"},{"location":"changelog/#version-1100","text":"2016-08-28 Fix: Support reading files larger than 2 GiB with GzipSource . Previously attempting to decompress such files would fail due to an overflow when validating the total length. Fix: Exit the watchdog thread after being idle for 60 seconds. This should make it possible for class unloaders to fully unload Okio. New: Okio.blackhole() returns a sink where all bytes written are discarded. This is Okio\u2019s equivalent of /dev/null . New: Encode a string with any charset using ByteString.encodeString() and decode strings in any charset using ByteString.string() . Most applications should prefer ByteString.encodeUtf8() and ByteString.utf8() unless it\u2019s necessary to support a legacy charset. New: GzipSink.deflater() makes it possible to configure the compression level.","title":"Version 1.10.0"},{"location":"changelog/#version-190","text":"2016-07-01 New: Pipe makes it easy to connect a producer thread to a consumer thread. Reads block until data is available to read. Writes block if the pipe\u2019s is full. Both sources and sinks support timeouts. New: BufferedSource.rangeEquals() makes it easy to compare a range in a stream to an expected value. This does the right thing: it blocks to load the data required return a definitive result. But it won\u2019t block unnecessarily. New: Timeout.waitUntilNotified() makes it possible to use nice timeout abstractions on Java\u2019s built-in wait/notify primitives. Fix: Don\u2019t return incorrect results when HashingSource does large reads. There was a bug where it wasn\u2019t traversing through the segments of the buffer being hashed. This means that HashingSource was returning incorrect answers for any writes that spanned multiple segment boundaries.","title":"Version 1.9.0"},{"location":"changelog/#version-180","text":"2016-05-02 New: BufferedSource.select(Options) API for reading one of a set of expected values. New: Make ByteString.toString() and Buffer.toString() friendlier. These methods return text if the byte string is valid UTF-8. New: APIs to match byte strings: indexOf() , startsWith() , and endsWith() .","title":"Version 1.8.0"},{"location":"changelog/#version-170","text":"2016-04-10 New: Change the segment size to 8 KiB. This has been reported to dramatically improve performance in some applications. New: md5() , sha1() , and sha256() methods on Buffer . Also add a sha1() method on ByteString for symmetry. New: HashingSource and HashingSink . These classes are Okio\u2019s equivalent to the JDK\u2019s DigestInputStream and DigestOutputStream . They offer convenient md5() , sha1() , and sha256() factory methods to avoid an impossible NoSuchAlgorithmException . New: ByteString.asByteBuffer() . Fix: Limit snapshot byte strings to requested size. Fix: Change write timeouts to have a maximum write size. Previously large writes could easly suffer timeouts because the entire write was subject to a single timeout. Fix: Recover from EBADF failures, which could be triggered by asynchronously closing a stream on older versions of Android. Fix: Don\u2019t share segments if doing so only saves a small copy. This should improve performance for all applications. Fix: Optimize BufferedSource.indexOfElement() and indexOf(ByteString) . Previously this method had a bug that caused it to be very slow on large buffers.","title":"Version 1.7.0"},{"location":"changelog/#version-160","text":"2015-08-25 New: BufferedSource.indexOf(ByteString) searches a source for the next occurrence of a byte string. Fix: Recover from unexpected AssertionError thrown on Android 4.2.2 and earlier when asynchronously closing a socket.","title":"Version 1.6.0"},{"location":"changelog/#version-150","text":"2015-06-19 Sockets streams now throw SocketTimeoutException . This builds on new extension point in AsyncTimeout to customize the exception when a timeout occurs. New: ByteString now implements Comparable . The comparison sorts bytes as unsigned: {@code ff} sorts after {@code 00}.","title":"Version 1.5.0"},{"location":"changelog/#version-140","text":"2015-05-16 Timeout exception changed. Previously Timeout.throwIfReached() would throw InterruptedIOException on thread interruption, and IOException if the deadline was reached. Now it throws InterruptedIOException in both cases. Fix: throw EOFException when attempting to read digits from an empty source. Previously this would crash with an unchecked exception. New: APIs to read and write UTF-8 code points without allocating strings. New: BufferedSink can now write substrings directly, potentially saving an allocation for some callers. New: ForwardingTimeout class.","title":"Version 1.4.0"},{"location":"changelog/#version-130","text":"2015-03-16 New: Read and write signed decimal and unsigned hexadecimal values in BufferedSource and BufferedSink . Unlike the alternatives, these methods don\u2019t do any memory allocations! New: Segment sharing. This improves the runtime of operations like Buffer.clone() and Buffer.copyTo() by sharing underlying segments between buffers. New: Buffer.snapshot() returns an immutable snapshot of a buffer as a ByteString . This builds on segment sharing so that snapshots are shallow, immutable copies. New: ByteString.rangeEquals() . New: ByteString.md5() and ByteString.sha256() . New: ByteString.base64Url() returns URL-safe Base64. The existing decoding method has been extended to support URL-safe Base64 input. New: ByteString.substring() returns a prefix, infix, or suffix. New: Sink now implements java.io.Flushable . Fix: Buffer.write(Source, long) now always writes fully. The previous behavior would return as soon as any data had been written; this was inconsistent with all other write() methods in the API. Fix: don\u2019t leak empty segments in DeflaterSink and InflaterSource. (This was unlikely to cause problems in practice.)","title":"Version 1.3.0"},{"location":"changelog/#version-120","text":"2014-12-30 Fix: Okio.buffer() always buffers for better predictability. Fix: Provide context when readUtf8LineStrict() throws. Fix: Buffers do not call through the Source on zero-byte writes.","title":"Version 1.2.0"},{"location":"changelog/#version-110","text":"2014-12-11 Do UTF-8 encoding natively for a performance increase, particularly on Android. New APIs: BufferedSink.emit() , BufferedSource.request() and BufferedSink.indexOfElement() . Fixed a performance bug in Buffer.indexOf()","title":"Version 1.1.0"},{"location":"changelog/#version-101","text":"2014-08-08 Added read(byte[]) , read(byte[], offset, byteCount) , and void readFully(byte[]) to BufferedSource . Refined declared checked exceptions on Buffer methods.","title":"Version 1.0.1"},{"location":"changelog/#version-100","text":"2014-05-23 Bumped release version. No other changes!","title":"Version 1.0.0"},{"location":"changelog/#version-090","text":"2014-05-03 Use 0 as a sentinel for no timeout. Make AsyncTimeout public. Remove checked exception from Buffer.readByteArray.","title":"Version 0.9.0"},{"location":"changelog/#version-080","text":"2014-04-24 Eagerly verify preconditions on public APIs. Quick return on Buffer instance equivalence. Add delegate types for Sink and Source. Small changes to the way deadlines are managed. Add append variant of Okio.sink for File. Methods to exhaust BufferedSource to byte[] and ByteString.","title":"Version 0.8.0"},{"location":"changelog/#version-070","text":"2014-04-18 Don\u2019t use getters in timeout. Use the watchdog to interrupt sockets that have reached deadlines. Add java.io and java.nio file source/sink helpers.","title":"Version 0.7.0"},{"location":"changelog/#version-061","text":"2014-04-17 Methods to read a buffered source fully in UTF-8 or supplied charset. API to read a byte[] directly. New methods to move all data from a source to a sink. Fix a bug on input stream exhaustion.","title":"Version 0.6.1"},{"location":"changelog/#version-060","text":"2014-04-15 Make ByteString serializable. New API: ByteString.of(byte[] data, int offset, int byteCount) New API: stream-based copy, write, and read helpers.","title":"Version 0.6.0"},{"location":"changelog/#version-050","text":"2014-04-08 Initial public release. Imported from OkHttp.","title":"Version 0.5.0"},{"location":"code_of_conduct/","text":"Open Source Code of Conduct \u00b6 At Square, we are committed to contributing to the open source community and simplifying the process of releasing and managing open source software. We\u2019ve seen incredible support and enthusiasm from thousands of people who have already contributed to our projects\u200a\u2014\u200aand we want to ensure our community continues to be truly open for everyone. This code of conduct outlines our expectations for participants, as well as steps to reporting unacceptable behavior. We are committed to providing a welcoming and inspiring community for all and expect our code of conduct to be honored. Square\u2019s open source community strives to: Be open : We invite anyone to participate in any aspect of our projects. Our community is open, and any responsibility can be carried by a contributor who demonstrates the required capacity and competence. Be considerate : People use our work, and we depend on the work of others. Consider users and colleagues before taking action. For example, changes to code, infrastructure, policy, and documentation may negatively impact others. Be respectful : We expect people to work together to resolve conflict, assume good intentions, and act with empathy. Do not turn disagreements into personal attacks. Be collaborative : Collaboration reduces redundancy and improves the quality of our work. We strive for transparency within our open source community, and we work closely with upstream developers and others in the free software community to coordinate our efforts. Be pragmatic : Questions are encouraged and should be asked early in the process to avoid problems later. Be thoughtful and considerate when seeking out the appropriate forum for your questions. Those who are asked should be responsive and helpful. Step down considerately : Members of every project come and go. When somebody leaves or disengages from the project, they should make it known and take the proper steps to ensure that others can pick up where they left off. This code is not exhaustive or complete. It serves to distill our common understanding of a collaborative, shared environment, and goals. We expect it to be followed in spirit as much as in the letter. Diversity Statement \u00b6 We encourage everyone to participate and are committed to building a community for all. Although we may not be able to satisfy everyone, we all agree that everyone is equal. Whenever a participant has made a mistake, we expect them to take responsibility for it. If someone has been harmed or offended, it is our responsibility to listen carefully and respectfully, and do our best to right the wrong. Although this list cannot be exhaustive, we explicitly honor diversity in age, culture, ethnicity, gender identity or expression, language, national origin, political beliefs, profession, race, religion, sexual orientation, socioeconomic status, and technical ability. We will not tolerate discrimination based on any of the protected characteristics above, including participants with disabilities. Reporting Issues \u00b6 If you experience or witness unacceptable behavior\u200a\u2014\u200aor have any other concerns\u200a\u2014\u200aplease report it by emailing codeofconduct@squareup.com . For more details, please see our Reporting Guidelines below. Thanks \u00b6 Some of the ideas and wording for the statements and guidelines above were based on work by the Twitter , Ubuntu , GDC , and Django communities. We are thankful for their work. Reporting Guide \u00b6 If you experience or witness unacceptable behavior\u200a\u2014\u200aor have any other concerns\u200a\u2014\u200aplease report it by emailing codeofconduct@squareup.com . All reports will be handled with discretion. In your report please include: Your contact information. Names (real, nicknames, or pseudonyms) of any individuals involved. If there are additional witnesses, please include them as well. Your account of what occurred, and if you believe the incident is ongoing. If there is a publicly available record (e.g. a mailing list archive or a public IRC logger), please include a link. Any additional information that may be helpful. After filing a report, a representative from the Square Code of Conduct committee will contact you personally. The committee will then review the incident, follow up with any additional questions, and make a decision as to how to respond. Anyone asked to stop unacceptable behavior is expected to comply immediately. If an individual engages in unacceptable behavior, the Square Code of Conduct committee may take any action they deem appropriate, up to and including a permanent ban from all of Square spaces without warning.","title":"Code of Conduct"},{"location":"code_of_conduct/#open-source-code-of-conduct","text":"At Square, we are committed to contributing to the open source community and simplifying the process of releasing and managing open source software. We\u2019ve seen incredible support and enthusiasm from thousands of people who have already contributed to our projects\u200a\u2014\u200aand we want to ensure our community continues to be truly open for everyone. This code of conduct outlines our expectations for participants, as well as steps to reporting unacceptable behavior. We are committed to providing a welcoming and inspiring community for all and expect our code of conduct to be honored. Square\u2019s open source community strives to: Be open : We invite anyone to participate in any aspect of our projects. Our community is open, and any responsibility can be carried by a contributor who demonstrates the required capacity and competence. Be considerate : People use our work, and we depend on the work of others. Consider users and colleagues before taking action. For example, changes to code, infrastructure, policy, and documentation may negatively impact others. Be respectful : We expect people to work together to resolve conflict, assume good intentions, and act with empathy. Do not turn disagreements into personal attacks. Be collaborative : Collaboration reduces redundancy and improves the quality of our work. We strive for transparency within our open source community, and we work closely with upstream developers and others in the free software community to coordinate our efforts. Be pragmatic : Questions are encouraged and should be asked early in the process to avoid problems later. Be thoughtful and considerate when seeking out the appropriate forum for your questions. Those who are asked should be responsive and helpful. Step down considerately : Members of every project come and go. When somebody leaves or disengages from the project, they should make it known and take the proper steps to ensure that others can pick up where they left off. This code is not exhaustive or complete. It serves to distill our common understanding of a collaborative, shared environment, and goals. We expect it to be followed in spirit as much as in the letter.","title":"Open Source Code of Conduct"},{"location":"code_of_conduct/#diversity-statement","text":"We encourage everyone to participate and are committed to building a community for all. Although we may not be able to satisfy everyone, we all agree that everyone is equal. Whenever a participant has made a mistake, we expect them to take responsibility for it. If someone has been harmed or offended, it is our responsibility to listen carefully and respectfully, and do our best to right the wrong. Although this list cannot be exhaustive, we explicitly honor diversity in age, culture, ethnicity, gender identity or expression, language, national origin, political beliefs, profession, race, religion, sexual orientation, socioeconomic status, and technical ability. We will not tolerate discrimination based on any of the protected characteristics above, including participants with disabilities.","title":"Diversity Statement"},{"location":"code_of_conduct/#reporting-issues","text":"If you experience or witness unacceptable behavior\u200a\u2014\u200aor have any other concerns\u200a\u2014\u200aplease report it by emailing codeofconduct@squareup.com . For more details, please see our Reporting Guidelines below.","title":"Reporting Issues"},{"location":"code_of_conduct/#thanks","text":"Some of the ideas and wording for the statements and guidelines above were based on work by the Twitter , Ubuntu , GDC , and Django communities. We are thankful for their work.","title":"Thanks"},{"location":"code_of_conduct/#reporting-guide","text":"If you experience or witness unacceptable behavior\u200a\u2014\u200aor have any other concerns\u200a\u2014\u200aplease report it by emailing codeofconduct@squareup.com . All reports will be handled with discretion. In your report please include: Your contact information. Names (real, nicknames, or pseudonyms) of any individuals involved. If there are additional witnesses, please include them as well. Your account of what occurred, and if you believe the incident is ongoing. If there is a publicly available record (e.g. a mailing list archive or a public IRC logger), please include a link. Any additional information that may be helpful. After filing a report, a representative from the Square Code of Conduct committee will contact you personally. The committee will then review the incident, follow up with any additional questions, and make a decision as to how to respond. Anyone asked to stop unacceptable behavior is expected to comply immediately. If an individual engages in unacceptable behavior, the Square Code of Conduct committee may take any action they deem appropriate, up to and including a permanent ban from all of Square spaces without warning.","title":"Reporting Guide"},{"location":"contributing/","text":"Contributing \u00b6 Keeping the project small and stable limits our ability to accept new contributors. We are not seeking new committers at this time, but some small contributions are welcome. If you\u2019ve found a security problem, please follow our bug bounty program. If you\u2019ve found a bug, please contribute a failing test case so we can study and fix it. Before code can be accepted all contributors must complete our Individual Contributor License Agreement (CLA) . Code Contributions \u00b6 Get working code on a personal branch with tests passing before you submit a PR: ./gradlew clean check Please make every effort to follow existing conventions and style in order to keep the code as readable as possible. Contribute code changes through GitHub by forking the repository and sending a pull request. We squash all pull requests on merge. Committer\u2019s Guides \u00b6 Releasing","title":"Contributing"},{"location":"contributing/#contributing","text":"Keeping the project small and stable limits our ability to accept new contributors. We are not seeking new committers at this time, but some small contributions are welcome. If you\u2019ve found a security problem, please follow our bug bounty program. If you\u2019ve found a bug, please contribute a failing test case so we can study and fix it. Before code can be accepted all contributors must complete our Individual Contributor License Agreement (CLA) .","title":"Contributing"},{"location":"contributing/#code-contributions","text":"Get working code on a personal branch with tests passing before you submit a PR: ./gradlew clean check Please make every effort to follow existing conventions and style in order to keep the code as readable as possible. Contribute code changes through GitHub by forking the repository and sending a pull request. We squash all pull requests on merge.","title":"Code Contributions"},{"location":"contributing/#committers-guides","text":"Releasing","title":"Committer's Guides"},{"location":"multiplatform/","text":"Multiplatform \u00b6 Okio is a Kotlin Multiplatform project. We\u2019re still completing our feature coverage. Compression (Deflater, Inflater, Gzip) \u00b6 JVM-only. Concurrency (Pipe, Timeouts, Throttler) \u00b6 JVM-only. Timeout is on all platforms, but only the JVM has a useful implementation. Core (Buffer, ByteString, Source, Sink) \u00b6 Available on all platforms. Filesystem \u00b6 Available on all platforms. For JavaScript this requires Node.js . Hashing \u00b6 Okio includes Kotlin implementations of MD5, SHA-1, SHA-256, and SHA-512. This includes both hash functions and HMAC functions. Okio uses the built-in implementations of these functions on the JVM.","title":"Multiplatform"},{"location":"multiplatform/#multiplatform","text":"Okio is a Kotlin Multiplatform project. We\u2019re still completing our feature coverage.","title":"Multiplatform"},{"location":"multiplatform/#compression-deflater-inflater-gzip","text":"JVM-only.","title":"Compression (Deflater, Inflater, Gzip)"},{"location":"multiplatform/#concurrency-pipe-timeouts-throttler","text":"JVM-only. Timeout is on all platforms, but only the JVM has a useful implementation.","title":"Concurrency (Pipe, Timeouts, Throttler)"},{"location":"multiplatform/#core-buffer-bytestring-source-sink","text":"Available on all platforms.","title":"Core (Buffer, ByteString, Source, Sink)"},{"location":"multiplatform/#filesystem","text":"Available on all platforms. For JavaScript this requires Node.js .","title":"Filesystem"},{"location":"multiplatform/#hashing","text":"Okio includes Kotlin implementations of MD5, SHA-1, SHA-256, and SHA-512. This includes both hash functions and HMAC functions. Okio uses the built-in implementations of these functions on the JVM.","title":"Hashing"},{"location":"releasing/","text":"Releasing \u00b6 Prerequisite: Sonatype (Maven Central) Account \u00b6 Create an account on the Sonatype issues site . Ask an existing publisher to open an issue requesting publishing permissions for com.squareup projects. Prerequisite: GPG Keys \u00b6 Generate a GPG key (RSA, 4096 bit, 3650 day) expiry, or use an existing one. You should leave the password empty for this key. $ gpg --full-generate-key Upload the GPG keys to public servers: $ gpg --list-keys --keyid-format LONG /Users/johnbarber/.gnupg/pubring.kbx ------------------------------ pub rsa4096/XXXXXXXXXXXXXXXX 2019-07-16 [SC] [expires: 2029-07-13] YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY uid [ultimate] John Barber <jbarber@squareup.com> sub rsa4096/ZZZZZZZZZZZZZZZZ 2019-07-16 [E] [expires: 2029-07-13] $ gpg --send-keys --keyserver keyserver.ubuntu.com XXXXXXXXXXXXXXXX Prerequisite: Gradle Properties \u00b6 Define publishing properties in ~/.gradle/gradle.properties : signing.keyId=1A2345F8 signing.password= signing.secretKeyRingFile=/Users/jbarber/.gnupg/secring.gpg signing.keyId is the GPG key\u2019s ID. Get it with this: $ gpg --list-keys --keyid-format SHORT signing.password is the password for this key. This might be empty! signing.secretKeyRingFile is the absolute path for secring.gpg . You may need to export this file manually with the following command where XXXXXXXX is the keyId above: $ gpg --keyring secring.gpg --export-secret-key XXXXXXXX > ~/.gnupg/secring.gpg Cutting a Release \u00b6 Update CHANGELOG.md . Set versions: export RELEASE_VERSION=X.Y.Z export NEXT_VERSION=X.Y.Z-SNAPSHOT Set environment variables with your Sonatype credentials . export SONATYPE_NEXUS_USERNAME=johnbarber export SONATYPE_NEXUS_PASSWORD=`pbpaste` Update, build, and upload: sed -i \"\" \\ \"s/VERSION_NAME=.*/VERSION_NAME=$RELEASE_VERSION/g\" \\ gradle.properties sed -i \"\" \\ \"s/\\\"com.squareup.okio:\\([^\\:]*\\):[^\\\"]*\\\"/\\\"com.squareup.okio:\\1:$RELEASE_VERSION\\\"/g\" \\ `find . -name \"README.md\"` ./gradlew clean publish Visit Sonatype Nexus to promote (close then release) the artifact. Or drop it if there is a problem! Tag the release, prepare for the next one, and push to GitHub. git commit -am \"Prepare for release $RELEASE_VERSION.\" git tag -a parent-$RELEASE_VERSION -m \"Version $RELEASE_VERSION\" sed -i \"\" \\ \"s/VERSION_NAME=.*/VERSION_NAME=$NEXT_VERSION/g\" \\ gradle.properties git commit -am \"Prepare next development version.\" git push && git push --tags","title":"Releasing"},{"location":"releasing/#releasing","text":"","title":"Releasing"},{"location":"releasing/#prerequisite-sonatype-maven-central-account","text":"Create an account on the Sonatype issues site . Ask an existing publisher to open an issue requesting publishing permissions for com.squareup projects.","title":"Prerequisite: Sonatype (Maven Central) Account"},{"location":"releasing/#prerequisite-gpg-keys","text":"Generate a GPG key (RSA, 4096 bit, 3650 day) expiry, or use an existing one. You should leave the password empty for this key. $ gpg --full-generate-key Upload the GPG keys to public servers: $ gpg --list-keys --keyid-format LONG /Users/johnbarber/.gnupg/pubring.kbx ------------------------------ pub rsa4096/XXXXXXXXXXXXXXXX 2019-07-16 [SC] [expires: 2029-07-13] YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY uid [ultimate] John Barber <jbarber@squareup.com> sub rsa4096/ZZZZZZZZZZZZZZZZ 2019-07-16 [E] [expires: 2029-07-13] $ gpg --send-keys --keyserver keyserver.ubuntu.com XXXXXXXXXXXXXXXX","title":"Prerequisite: GPG Keys"},{"location":"releasing/#prerequisite-gradle-properties","text":"Define publishing properties in ~/.gradle/gradle.properties : signing.keyId=1A2345F8 signing.password= signing.secretKeyRingFile=/Users/jbarber/.gnupg/secring.gpg signing.keyId is the GPG key\u2019s ID. Get it with this: $ gpg --list-keys --keyid-format SHORT signing.password is the password for this key. This might be empty! signing.secretKeyRingFile is the absolute path for secring.gpg . You may need to export this file manually with the following command where XXXXXXXX is the keyId above: $ gpg --keyring secring.gpg --export-secret-key XXXXXXXX > ~/.gnupg/secring.gpg","title":"Prerequisite: Gradle Properties"},{"location":"releasing/#cutting-a-release","text":"Update CHANGELOG.md . Set versions: export RELEASE_VERSION=X.Y.Z export NEXT_VERSION=X.Y.Z-SNAPSHOT Set environment variables with your Sonatype credentials . export SONATYPE_NEXUS_USERNAME=johnbarber export SONATYPE_NEXUS_PASSWORD=`pbpaste` Update, build, and upload: sed -i \"\" \\ \"s/VERSION_NAME=.*/VERSION_NAME=$RELEASE_VERSION/g\" \\ gradle.properties sed -i \"\" \\ \"s/\\\"com.squareup.okio:\\([^\\:]*\\):[^\\\"]*\\\"/\\\"com.squareup.okio:\\1:$RELEASE_VERSION\\\"/g\" \\ `find . -name \"README.md\"` ./gradlew clean publish Visit Sonatype Nexus to promote (close then release) the artifact. Or drop it if there is a problem! Tag the release, prepare for the next one, and push to GitHub. git commit -am \"Prepare for release $RELEASE_VERSION.\" git tag -a parent-$RELEASE_VERSION -m \"Version $RELEASE_VERSION\" sed -i \"\" \\ \"s/VERSION_NAME=.*/VERSION_NAME=$NEXT_VERSION/g\" \\ gradle.properties git commit -am \"Prepare next development version.\" git push && git push --tags","title":"Cutting a Release"},{"location":"security/","text":"Security Policy \u00b6 Supported Versions \u00b6 Version Supported 2.x \u2705 1.x \u2705 Reporting a Vulnerability \u00b6 Square recognizes the important contributions the security research community can make. We therefore encourage reporting security issues with the code contained in this repository. If you believe you have discovered a security vulnerability, please follow the guidelines at https://bugcrowd.com/squareopensource","title":"Security"},{"location":"security/#security-policy","text":"","title":"Security Policy"},{"location":"security/#supported-versions","text":"Version Supported 2.x \u2705 1.x \u2705","title":"Supported Versions"},{"location":"security/#reporting-a-vulnerability","text":"Square recognizes the important contributions the security research community can make. We therefore encourage reporting security issues with the code contained in this repository. If you believe you have discovered a security vulnerability, please follow the guidelines at https://bugcrowd.com/squareopensource","title":"Reporting a Vulnerability"}]}